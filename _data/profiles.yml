---
- Submission: proj102s1
  Status (This Stage): Accept Wave 2 (Confirmed)
  First/Given Names (first): Shu
  Last/Family Name (first): Hu
  Email (first): hu968@purdue.edu
  Company/Institution (first): Purdue University
  Department (first): School of Applied and Creative Computing
  Photograph (first): 'png Information Type: pngSize: 219KBUploaded: Sep 16MD5: 38996968c22dbe4f8e07f460d98c9ef6Original
    Name: Shu Hu.png view move to AWS'
  Website (first): https://web.ics.purdue.edu/~hu968/
  SRP Project Title (first): Improving Fairness in Detecting AI-Synthesized Fake Multimedia
  What is the NAIRR Project Name? (first): Improving Fairness in Detecting AI-Synthesized
    Fake Multimedia
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Artificial Intelligence and Intelligent Systems; Computer Science;
    Media and communications; Other Computer and Information Sciences; Other Engineering
    and Technologies; Performance Evaluation and Benchmarking; Visualization and Human-Computer
    Systems
  Brief Abstract (200 words) (first): DeepFake, a term increasingly mentioned in the
    news and social media, refers to highly realistic fake images, and videos created
    using AI algorithms. Combating DeepFake technology requires a comprehensive strategy
    that extends well beyond the realm of mere detection, emphasizing the responsible
    design, development, and deployment of technologies. This also known as responsible
    forensics, focuses on applying forensic science to digital content ethically,
    ensuring that actions to identify and mitigate DeepFakes meet high ethical standards
    and respect for human rights. At the heart of responsible forensics lies the commitment
    to fairness, especially important in the context of generative AI. It is crucial
    for detection tools to be crafted and used in ways that prevent unintentional
    bias against certain individuals or groups, thus upholding justice and equality
    in the digital realm. Therefore, our goal is to improve fairness in detecting
    novel DeepFakes.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): Python
    Programming Skill.
  Lightning Talk Title (Maximum 10 words): Improving Fairness in Detecting AI-Synthesized
    Fake Multimedia
  Keywords (Maximum 20 words): DeepFake Detection; Media Forensics; Generalization;
    AI-generated Media
  Biography (Maximum 200 words): Dr. Shu Hu is an assistant professor in the School
    of Applied and Creative Computing and the Director of the Purdue Machine Learning
    and Media Forensics (M2) Lab at Purdue University. He was a Post-Doctoral Fellow
    at the Heinz College of Carnegie Mellon University from 2022 to 2023. He received
    my Ph.D. degree in Computer Science and Engineering from the University at Buffalo,
    SUNY in 2022. He is the recipient of the National AI Research Resource (NAIRR)
    Pilot award (2024), the National Science Foundation CRII Award (2024), the Machine
    Intelligence Research Outstanding Reviewer Award (2023), and SUNY Buffalo's CSE
    Best PhD Dissertation Award (2022). His research interests include machine learning,
    media forensics, and computer vision.
- Submission: proj104s1
  Status (This Stage): Accept Wave 2 (Confirmed)
  First/Given Names (first): Armstrong
  Last/Family Name (first): Aboah
  Email (first): armstrong.aboah@ndsu.edu
  Company/Institution (first): North Dakota State University
  SRP Project Title (first): 'PRIME: A Foundational Predictive Real-time Intersection
    Monitoring Engine'
  What is the NAIRR Project Name? (first): 'PRIME: A Foundational Predictive Real-time
    Intersection Monitoring Engine'
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Artificial Intelligence and Intelligent Systems; Civil Engineering;
    Computer Science
  Brief Abstract (200 words) (first): Traffic intersections remain critical points
    of vulnerability in transportation infrastructure, accounting for 20% of vehicular
    accidents and over 7,000 annual fatalities in the United States. Current intersection
    monitoring systems, relying on basic motion detection or single-class object detection,
    struggle with complex scenarios involving multiple road users and varying environmental
    conditions. This research proposes PRIME (Predictive Real-time Intersection Monitoring
    Engine), a foundational traffic intersection monitoring algorithm that integrates
    advanced deep learning techniques for multi-class video object detection and trajectory
    prediction. This project directly aligns with NAIRR priority areas by creating
    open-source foundation models for specific applications and utilizing experimental
    data from sensors and detectors. The proposed system employs a novel object detection
    architecture with enhanced feature pyramid networks and combines transformer encoders
    with graph neural networks to achieve robust object detection and accurate 5-second
    trajectory predictions. Our technical objectives include developing a multi-class
    detection system with over 95% accuracy, implementing proactive trajectory prediction,
    and generating anonymous traffic patterns for urban planning. The project will
    be executed utilizing TACC Frontera GPU resources for model development and training.
    We will also release our codebase and make our annotated dataset publicly available
    with the aim of establishing a common foundation for intersection monitoring systems.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): A
    good programming background, like Python. Familiarity with computer vision.
  Lightning Talk Title (Maximum 10 words): Towards a safe and smart intersection
  Keywords (Maximum 20 words): Machine learning, Safety, Intersection, trajectory
  Biography (Maximum 200 words): I am an Assistant Professor at the North Dakota State
    University. An ingenious and resourceful Transportation Data Scientist with a
    proven track record of success in research and hands-on experience developing
    cutting-edge database solutions, statistical modeling, data products, and computer
    vision systems aimed at improving transportation system management and operations.
    Has worked as an architect and application developer on a variety of projects
    that required the use of data mining and machine learning models to solve large-scale,
    complex, and difficult transportation problems. I am broadly interested in computer
    vision and machine learning. My research involves visual reasoning, vision and
    language, image generation, air taxis, naturalistic studies, and autonomous vehicles.
- Submission: proj105s1
  Status (This Stage): Accept Wave 2 (Confirmed)
  First/Given Names (first): Yupeng
  Last/Family Name (first): Zhang
  Email (first): yupeng@alumni.caltech.edu
  Company/Institution (first): University of California, Los Angeles
  Photograph (first): 'jpg Information Type: jpgSize: 85KBUploaded: Sep 16MD5: 8ff1a162ebcfed07230b96d9a1422d2bOriginal
    Name: self_2024.jpg view move to AWS'
  Website (first): https://orcid.org/0000-0001-7149-451X
  SRP Project Title (first): Iterative learning for materials and structures
  What is the NAIRR Project Name? (first): Geometry Effects on Iterative Learning
    for Multiscale Modeling of History-Dependent Metamaterials
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Applied Mathematics; Artificial Intelligence and Intelligent
    Systems; Civil Engineering; Computer Science; Geology and Solid Earth Sciences;
    Informatics, Analytics and Information Science; Infrastructure and Instrumentation;
    Materials Engineering; Mechanical Engineering; Other Computer and Information
    Sciences; Other Engineering and Technologies; Statistics and Probability; Visualization
    and Human-Computer Systems
  Brief Abstract (200 words) (first): A big challenge in advancing AI methods that
    enable scientific discovery is to understand what kinds of data are necessary
    to obtain accurate and transferable surrogate models. We explored this question
    in the context of the history-dependent behavior of materials and structures.
    We introduced an iterative approach where we used a rich arbitrary class of trajectories
    to train an initial model. We then iteratively updated the class of trajectories
    with those that arise in large-scale simulation and used transfer learning to
    update the model. We showed that such an approach converges to a highly accurate
    surrogate, and one that is transferable. In our current NAIRR Pilot project, we
    are investigating how geometry influences iterative learning in multiscale modeling
    of history-dependent metamaterials. Through the Sustainable Research Pathways
    (SRP) Program, we aim to develop AI/ML-based digital twins of physical materials
    and structures under various boundary conditions. The digital twins will serve
    as fast and reliable surrogates for multiscale modeling, optimization, and inverse
    design. This research connects AI/ML with mechanics, materials, structures, and
    design. Participants will gain experience with machine learning, numerical simulation,
    with applications spanning mechanical civil, and materials engineering.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): Participants
    with interests in artificial intelligence, machine learning, numerical modeling,
    or materials / structures / mechanics are encouraged to apply. A background in
    engineering, computer science, applied math, applied statistics, or related fields
    is helpful, but not required. Curiosity and enthusiasm are especially valuable.
  Lightning Talk Title (Maximum 10 words): AI/ML model for complex mechanical systems
  Keywords (Maximum 20 words): solid mechanics, materials characterization, Bayesian
    statistics, inverse problems, AI/ML, multiscale modeling of complex system, thermo-magneto-mechanical
    couplings.
  Biography (Maximum 200 words): Yupeng Zhang is currently with the Department of
    Mechanical and Aerospace Engineering at the University of California, Los Angeles
    (UCLA). He received his Ph.D. in Materials Science and Engineering from Texas
    A&M University, specializing in solid mechanics, Bayesian statics, and materials
    characterization, followed by postdoctoral positions at Northwestern University,
    and the California Institute of Technology. Zhang is a member of the ASCE - EMI
    Machine Learning in Mechanics Committee and the recipient of NAIRR grant as a
    single PI, the Future Faculty Symposium Travel Award from the Society of Engineering
    Science in 2023, the Clearfield Materials Fellowship at Texas A&M University,
    and the Mitacs Globalink Research internship from Mitacs Canada. Zhang has mentored
    over ten graduate and undergraduate students and serves as a reviewer for such
    as Journal of Applied Mechanics (ASME), Journal of Engineering Mechanics (ASCE),
    Mechanics of Materials (Elsevier), European Journal of Mechanics / A Solids (Elsevier),
    Journal of Materials Research (Springer), Journal of Engineering Materials and
    Technology (ASME), Experimental Mechanics (Society for Experimental Mechanics,
    SEM), Physics of Fluids(AIP). His research interests include solid mechanics,
    materials characterization Bayesian statistics, inverse problems, and AI/machine
    learning, focusing on multiscale modeling of complex system, and thermo-magneto-mechanical
    couplings.
- Submission: proj106s1
  Status (This Stage): Accept Wave 2 (Confirmed)
  First/Given Names (first): Zhuangdi
  Last/Family Name (first): Zhu
  Email (first): zzhu24@gmu.edu
  Company/Institution (first): George Mason University
  Website (first): http://zhuangdizhu.github.io/
  SRP Project Title (first): Developing Engaging AI Chatbots to Enhance Senior Well-being
  What is the NAIRR Project Name? (first): Developing Engaging AI Chatbots to Enhance
    Senior Well-being
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Artificial Intelligence and Intelligent Systems; Health Sciences
  Brief Abstract (200 words) (first): The mental well-being of the elderly population
    is a growing concern. According to the World Health Organization, approximately
    $14\%$ of adults aged 60 and over experience mental disorders, and the issues
    are often compounded by loneliness and social isolation. Large Language Models
    (LLMs) offer a promising solution by enabling meaningful, multi-turn dialogues.
    Leveraging the advanced natural language processing utility of LLMs, we aim to
    develop an AI chatbot specifically designed for seniors. Our research goal is
    to create an LLM-empowered dialog system that ensures engaging conversations for
    senior participants, thus supporting their cognitive functions and offering accessible
    interaction tools alongside traditional human interviews. It also underpins research
    for crucial applications such as detecting Mild Cognitive Impairment and intervening
    in the early stages of dementia.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): Successfully
    led at least one project in a relevant domain or involving large language models
    (LLMs). + First-author experience in submitting research papers to leading ML/AI
    conferences. + Strong background in LLM-focused research programming and prompt
    engineering.
  Lightning Talk Title (Maximum 10 words): Developing AI Chatbots for Improving Cognitive
    Health
  Keywords (Maximum 20 words): Agentic AI Chatbot Cognitive Health User Study
  Biography (Maximum 200 words): 'Zhuangdi Zhu is an assistant professor at the Department
    of Cyber Security Engineering of George Mason University. Prior to that, she worked
    as a senior Data & Applied Scientist for Microsoft. I received my Ph.D. degree
    from the Department of Computer Science and Engineering at Michigan State University.
    Her research centers around Accountable AI, through efforts in two directions:
    (1) advancing interactive AI to learn and reason over long horizons through principled
    Reinforcement Learning, and (2) decentralizing AI to the edge while balancing
    security, privacy, and efficiency.'
- Submission: proj107s1
  Status (This Stage): Accept Wave 2 (Confirmed)
  First/Given Names (first): Naeemul
  Last/Family Name (first): Hassan
  Email (first): nhassan@umd.edu
  Company/Institution (first): University of Maryland
  Department (first): College of Information
  SRP Project Title (first): AI for Quality Healthcare Information
  What is the NAIRR Project Name? (first): Advancing Explainable LLM to Bridge the
    Knowledge-Practice Gap in Healthcare Communication
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Artificial Intelligence and Intelligent Systems; Computer Science;
    Health Sciences; Informatics, Analytics and Information Science; Media and communications;
    Other Computer and Information Sciences; Other Medical Sciences; Statistics and
    Probability; Visualization and Human-Computer Systems
  Brief Abstract (200 words) (first): This project investigates how large language
    models (LLMs) can help bridge the gap between scientific best practices and healthcare
    journalism. Research shows that news coverage of medical treatments often omits
    critical details such as harms, evidence quality, or alternatives leading to public
    misunderstanding and even harmful health decisions. While frameworks exist to
    assess the quality of healthcare news, they are labor-intensive and not scalable.
    Our project explores the potential of LLMs (e.g., GPT models, LLaMA) to automatically
    evaluate healthcare news articles against science-informed criteria, provide explainable
    feedback, and support journalists in improving reporting quality. We will test
    models on a curated dataset of 2,000 expert-annotated healthcare articles and
    extend the evaluation to larger datasets.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): The
    project blends computational journalism, natural language processing, and human-computer
    interaction to advance both AI explainability and its practical applications in
    healthcare communication. Relevant expertise- Interest in AI/LLMs, computational
    journalism, or healthcare communication Familiarity with Python, machine learning,
    or NLP libraries (e.g., Hugging Face, OpenAI API) Experience with data annotation,
    text analysis, or evaluation frameworks Curiosity about interdisciplinary research
    that combines computer science, journalism, and public health Strong analytical
    and communication skills, with an openness to learning across fields
  Lightning Talk Title (Maximum 10 words): Advancing Explainable LLM to Bridge the
    Knowledge-Practice Gap in Healthcare
  Keywords (Maximum 20 words): Artificial Intelligence; Large Language Model; Health
    Information; Natural Language Processing
  Biography (Maximum 200 words): Dr. Naeemul Hassan is an Associate Professor in the
    Philip Merrill College of Journalism at the University of Maryland, jointly appointed
    with the College of Information Studies (iSchool). His research lies at the intersection
    of computational journalism, data science, and artificial intelligence, focusing
    on combating misinformation and enhancing the transparency and efficiency of news
    production. Dr. Hassan’s work combines natural language processing, machine learning,
    and human-centered approaches to improve how information is produced, verified,
    and consumed.
- Submission: proj109s1
  Status (This Stage): Accept Wave 2 (Confirmed)
  First/Given Names (first): Xiao
  Last/Family Name (first): Wang
  Email (first): xiaowangatpurdue@gmail.com
  Company/Institution (first): Oak Ridge National Laboratory
  Photograph (first): 'jpg Information Type: jpgSize: 756KBUploaded: Sep 17MD5: 3e4ead91c3b1185356294792f54a5deeOriginal
    Name: IMG_0151.JPG view move to AWS'
  Website (first): https://www.ornl.gov/staff-profile/xiao-wang
  SRP Project Title (first): Computing-Efficient Training for Large-Scale Vision Transformer
    Foundation Models
  What is the NAIRR Project Name? (first): Computing-Efficient Training for Large-Scale
    Vision Transformer Foundation Models
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Artificial Intelligence and Intelligent Systems; Computer Science
  Brief Abstract (200 words) (first): Vision Transformer (ViT) is a powerful AI architecture
    for computer vision that is used by most imaging foundation models due to its
    effectiveness in discerning complex visual patterns across many tasks. However,
    training large-scale ViT foundation models requires considerable computing resources,
    leading to a significant energy footprint for training. For example, Open-AI’s
    SORA video generator model was trained on more than 10,000 NVIDIA H-100 GPUs and
    the training took more than a month on a supercomputer. The energy consumption
    for training SORA was equivalent to the total annual energy consumption of 300
    US households. This one-year project aims to improve ViT scaling algorithms computing
    efficiency, reducing AI development cycle and training time. We will develop a
    training framework optimized for hardware-conscious scaling and computing efficiency,
    specifically tailored for large-scale ViT models.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): AI,
    efficient computing
  Lightning Talk Title (Maximum 10 words): Energy Efficient Vision Transformer Training
    Framework For Exascale Foundation Models
  Keywords (Maximum 20 words): vision transformer, exascale foundation model, high
    performance computing, energy efficiency
  Biography (Maximum 200 words): Dr. Xiao Wang is a research staff scientist in the
    Computational Science and Engineering Division at Oak Ridge National Laboratory
    (ORNL). He earned dual Bachelor's degrees in Mathematics and Computer Science
    from Saint John’s University, MN (2012), and completed his M.S. and Ph.D. in Electrical
    and Computer Engineering at Purdue University (2016–2017) under Dr. Charles Bouman
    and Dr. Samuel Midkiff. Before joining ORNL in 2021, he conducted postdoctoral
    research at Harvard Medical School and Boston Children’s Hospital, focusing on
    medical imaging. Dr. Wang’s research lies at the intersection of artificial intelligence
    (AI), high-performance computing (HPC), and computational imaging. He develops
    algorithms that integrate AI, imaging physics, and HPC to enable high-resolution,
    data-efficient imaging across modalities such as X-ray, CT, MRI, electron tomography,
    and satellite imaging, with applications in medicine, biology, climate science,
    and national security. He received the 2022 AAPM Truth CT Reconstruction Challenge
    award, was a finalist for the ACM Gordon Bell Prize in 2017 and 2024, and received
    the 2024 HPCWire Top Supercomputing Achievement Award. His current work focuses
    on scalable, energy-efficient, and trustworthy Vision Transformer foundation models
    for large-scale imaging applications.
- Submission: proj113s1
  Status (This Stage): Accept Wave 2 (Confirmed)
  First/Given Names (first): Yang
  Last/Family Name (first): Liu
  Email (first): y-liu@tamu.edu
  Company/Institution (first): Texas A&M University
  Department (first): Department of Nuclear Engineering
  SRP Project Title (first): LLM-Enhanced Cyber-Physical Testbed for Advanced Reactor
    Monitoring and Predictive Maintenance
  What is the NAIRR Project Name? (first): LLM-Enhanced Cyber-Physical Testbed for
    Advanced Reactor Monitoring and Predictive Maintenance
  'Please select all the topical areas that apply to your project: (first)': Artificial
    Intelligence and Intelligent Systems; Mechanical Engineering; Other Engineering
    and Technologies
  Brief Abstract (200 words) (first): This project aims to harness cutting-edge large
    language models (LLMs) to enhance real-time monitoring, anomaly detection, and
    predictive maintenance in a thermal-fluid facility designed for advanced nuclear
    reactors. By integrating sensor data, experimental logs, and domain-specific knowledge,
    the LLM-based platform will identify off-normal events and potential cybersecurity
    threats, providing timely diagnostics to operators. The resulting methods and
    tools will be published openly, enabling broader adoption within the nuclear industry
    and fostering safer, more efficient reactor operations.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): Generative
    AI, Large language model, Retrieval-Augmented-Generation, AI Agents, Context engineering.
  Lightning Talk Title (Maximum 10 words): Domain Knowledge-Enhanced Generative AI
    for Advanced Energy Research and Development
  Keywords (Maximum 20 words): Generative AI; Advanced Energy Systems; Automating
    Engineering Workflow; Real-Time Remote Monitoring and Control; Modeling and Simulation;
    Retrieval Augmented Generation
  Biography (Maximum 200 words): Dr. Yang Liu is an Assistant Professor of Nuclear
    Engineering at Texas A&M University. He leads the Scientific Machine learning
    for Advanced Reactor Technologies (SMART) lab and serves as the director of the
    Generative AI for Science and Engineering (GAISE) Lab under Texas A&M Institute
    of Data Science. Prior to joining TAMU, he held positions as staff at Argonne
    and postdoc at University of Michigan. His research focuses on the intersection
    between AI/ML and advanced energy systems, including (a). Physics-informed machine
    learning; (b). Digital twin-enhanced experimentation; and (c). Generative AI for
    science and engineering. Dr. Liu has published more than 50 papers in refereed
    journals and conference proceedings. He is a recipient of US. Department of Energy
    Nuclear Energy Office's Distinguished Early Career Award in 2024.
- Submission: proj117s1
  Status (This Stage): Accept Wave 2 (Confirmed)
  First/Given Names (first): Anima
  Last/Family Name (first): Anandkumar
  Email (first): anima@caltech.edu
  Company/Institution (first): Caltech
  Department (first): Computing and Mathematical Sciences
  Website (first): https://tensorlab.cms.caltech.edu/
  SRP Project Title (first): Neural Operators for Scalable and Sustainable Scientific
    Modeling
  What is the NAIRR Project Name? (first): Aligning AI models for scientific simulations
    under a physics-informed framework
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Applied Mathematics; Artificial Intelligence and Intelligent
    Systems; Computer Science; Other Computer and Information Sciences
  Brief Abstract (200 words) (first): Addressing global sustainability challenges
    requires fast, accurate, and generalizable modeling of complex systems in energy,
    climate, and infrastructure. Traditional high-fidelity simulations are often too
    slow and computationally expensive for timely exploration, design, and decision-making.
    This project leverages and advances neural operator frameworks to accelerate scientific
    simulations while adhering to known physical laws. By combining the expressiveness
    and inference speed of deep learning architectures with physics knowledge, these
    neural operators provide predictive surrogates for systems governed by partial
    differential equations, enabling scalable, energy-efficient computation at previously
    inaccessible scales. In this research, embedding physical constraints ensure sreliable
    predictions, generalizes modeling across diverse domains, and enables inverse
    design to identify system configurations that meet performance goals. Uncertainty
    quantification and formal verification in Lean (a theorem prover) provide further
    guarantees of correctness and reliability. Physics-informed enhancements, operator-based
    multi-scale learning, and robust modeling strategies ensure accurate long-term
    behavior and broad applicability to complex real-world systems. These tools support
    high-impact simulations for renewable energy, environmental resilience, and critical
    infrastructure planning. By releasing open-source frameworks, fostering accessibility,
    and prioritizing usability, this work empowers scientists, engineers, and students
    worldwide to harness advanced neural operators for transformative discovery, informed
    decision-making, and sustainable, verifiable solutions to urgent global challenges.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): "<ul><li>Knowledge
    of machine learning fundamentals</li><li>Strong programming skills and experience
    with scientific computing and deep learning libraries (e.g., Python, PyTorch)</li><li>Familiarity
    with differential equations and numerical methods</li><li>Interest in computational
    modeling and applying AI to scientific problems</li><li>Enthusiastic and proactive
    in exploring new research questions, methods, and learning opportunities</li><li>Open-minded
    and adaptable, eager to engage with diverse scientific approaches and perspectives</li><li>Passion
    for interdisciplinary research bridging AI and physical sciences</li><li>Effective
    communication skills</li><li>(Optional) Familiarity with theorem provers such
    as Lean or an interest in learning them can be helpful for certain specific directions,
    though not required for most directions</li></ul>"
  Lightning Talk Title (Maximum 10 words): Neural Operators for Scalable and Sustainable
    Scientific Modeling
  Keywords (Maximum 20 words): AI for science; neural operators; physics-informed
    ML; accelerating simulations and scientific discovery; inverse design;
  Biography (Maximum 200 words): Anima has made fundamental contributions to AI that
    is revolutionizing scientific modeling and discovery. She invented Neural Operators
    for learning multiscale phenomena that frequently occur in nature, such as fluid
    dynamics, material modeling and wave propagation. She employed Neural Operators
    to train the first AI-based high-resolution weather model, tens of thousands of
    times faster than existing physics-based forecasting. Her AI algorithms have enabled
    many other scientific advances such as modeling plasma evolution in nuclear fusion,
    enabling safer autonomous drone flights, and designing novel medical devices,
    drugs, and functional enzymes. Earlier in her career, Anima spearheaded the development
    of tensor methods, probabilistic latent variable models, and analysis of non-convex
    optimization. Anima is Bren Professor at Caltech. She previously was a Senior
    Director of AI Research at NVIDIA and Principal Scientist at Amazon Web Services.
    She received her B.Tech from IIT Madras, and her Ph.D. from Cornell University.
    She did her postdoctoral research at MIT and an assistant professorship at UC
    Irvine. She has received several honors such as the IEEE fellowship, Alfred. P.
    Sloan Fellowship, NSF Career Award, and Faculty Fellowships from Microsoft, Google,
    Facebook, and Adobe. She is part of the World Economic Forum's Expert Network.
- Submission: proj119s1
  Status (This Stage): Accept (Confirmed)
  First/Given Names (first): Megan
  Last/Family Name (first): Phinney
  Email (first): mphinney@lanl.gov
  Company/Institution (first): Los Alamos National Laboratory (LANL)
  SRP Project Title (first): Super Containers at Super Scale
  What is the HPSF Project Name? (first): Charliecloud
  'Please select all the topical areas that apply to your project: (first)': High
    Performance Computing
  Brief Abstract (200 words) (first): 'Your job will be software development on Charliecloud:
    programming; writing and editing documentation; and analyzing bug reports and
    feature requests. You will participate in the broader project, such as internal/external
    collaborations, strategy planning, code review, and research. You will collaborate
    with colleagues inside and outside LANL, both formally and informally, in both
    written and oral contexts. Finally, you will participate in technical events (e.g.,
    lectures) and professional development activities across LANL. This is a mentored
    role, and your success will be a top priority for your mentor. Expect to see them
    on a daily basis for detailed technical and professional guidance and be fully
    on-site to facilitate better collaboration in this junior role.'
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): An
    understanding how the command line works, Linux/Unix, Shell commands, Git, Python,
    C, and POSIX sh programming
  Lightning Talk Title (Maximum 10 words): Super Charliecloud Containers at Super
    Scale
  Keywords (Maximum 20 words): Containers; Linux/Unix Shell commands; Git; Python;
    C; POSIX sh programming
  Biography (Maximum 200 words): Megan earned a B.S. in computer engineering at Iowa
    State University in 2022. She joined Los Alamos National Laboratory in 2020 as
    an undergrad student and was promoted to staff scientist in 2022. At LANL, she
    works on container runtimes and workflows as a part of the Charliecloud project.
    She also provides user support for HPC systems. In her free time, she enjoys reading,
    hiking, and playing with her pit bull.
- Submission: proj123s1
  Status (This Stage): Accept Wave 2 (Confirmed)
  First/Given Names (first): Edgar
  Last/Family Name (first): Lobaton
  Email (first): edgar.lobaton@ncsu.edu
  Company/Institution (first): North Carolina State University
  SRP Project Title (first): AI-Guided Learning in JupyterHub Environments
  What is the NAIRR Project Name? (first): Providing GPU Resources for Deep Learning
    at NC State
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Educational Sciences; Electrical, Electronic, and Information
    Engineering
  Brief Abstract (200 words) (first): Ready to build the future of coding education?
    This high-impact research project invites motivated students to integrate Large
    Language Models (LLMs) into the JupyterHub platform for technical coursework,
    with the core goal of transforming the LLM from a passive tutor into an active,
    reflective guide. You'll be responsible for developing and deploying the LLM interface
    within Jupyter Notebooks, implementing a fine-grained tracking and logging mechanism
    to capture student-LLM interaction data, and creating prompt engineering strategies
    that strictly enforce the LLM's role as a "navigator", while offering directional
    guidance, samples and logic critiques rather than direct solutions. This work
    lies at the critical intersection of AI, Human-Computer Interaction, and Educational
    Technology, offering a unique opportunity to directly influence how the next generation
    of technical professionals learns to code by leveraging AI as a powerful learning
    partner.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): "-
    Proficiency in Python programming - Familiarity with the use of the API for any
    LLM (e.g., OpenAI API) - [Desired but not required] Familiarity with Kubernetes"
  Any other comments (first): As part of this project, you will also help with expanding
    on the features of our existing JupyterHub infrastructure through JetStream2.
  Lightning Talk Title (Maximum 10 words): LLMs as Co-Pilots in Scientific Modeling,
    Coding and Learning
  Keywords (Maximum 20 words): Code assistant; LLMs; AI as a guide; Physics Modeling
  Biography (Maximum 200 words): Edgar J. Lobaton is a Professor in the Department
    of Electrical and Computer Engineering (ECE) at North Carolina State University
    (NCSU). He joined the department in 2011. Lobaton earned his B.S. in Mathematics
    and Electrical engineering from Seattle University in 2004. He completed his Ph.D.
    in Electrical Engineering and Computer Sciences from the University of California,
    Berkeley in 2009. Lobaton was engaged in research at Alcatel-Lucent Bell Labs
    in 2005 and 2009. He was awarded the NSF CAREER Award in 2016. He was also awarded
    the 2009 Computer Innovation Fellows post-doctoral fellowship and conducted research
    in the Department of Computer Science at the University of North Carolina (UNC)
    at Chapel Hill from 2009 until 2011. In 2023, he received the William F. Lane
    Outstanding Teaching from the ECE Department. In 2024, he received the University
    Faculty Scholars and the Outstanding Teacher Awards from NC State. His research
    focuses on the integration of AI, and physical and probabilistic modeling applied
    to cyber-physical systems in areas such as wearable health monitoring, rehabilitation
    robotics, agriculture and biological imaging.
- Submission: proj125s1
  Status (This Stage): Accept (Confirmed)
  First/Given Names (first): Kenneth
  Last/Family Name (first): Moreland
  Email (first): morelandkd@ornl.gov
  Company/Institution (first): Oak Ridge National Laboratory (ORNL)
  Website (first): https://www.kennethmoreland.com/
  SRP Project Title (first): Advanced Scientific Visualization with Viskores
  What is the HPSF Project Name? (first): Viskores
  'Please select all the topical areas that apply to your project: (first)': Computer
    Science; High Performance Computing; Open Source Software; Software Engineering;
    Visualization and Human-Computer Systems
  Brief Abstract (200 words) (first): This project involves the Viskores software
    library (https://github.com/Viskores/viskores). This library provides functionality
    to process data that, most often, is generated by physics simulations and provides
    visual representations to improve data understanding. The Viskores algorithm performs
    numerous types of computational geometry to extract visually meaning features
    from data such as contour surfaces from fields and tracing paths within flow.
    Viskores is also responsible for the rendering of such features using a variety
    of computer graphics techniques. The specifics of the project will be tailored
    to the intern’s interests and abilities. The primary needs of the project involve
    an expansion of Viskores rendering capabilities, optimization of Viskores algorithms,
    and improved Viskores documentation.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): C++;
    Familiarity with entering commands in a command prompt (e.g, terminal, xterm,
    powershell, etc.)
  Lightning Talk Title (Maximum 10 words): Visualization at Exascale with Viskores
  Keywords (Maximum 20 words): visualization; HPC; GPU
  Biography (Maximum 200 words): Dr. Kenneth Moreland is a senior research scientist
    at Oak Ridge National Laboratory. He received BS degrees in computer science and
    in electrical engineering from the New Mexico Institute of Mining and Technology
    in 1997. He received MS and Ph.D. degrees in computer science from the University
    of New Mexico in 2000 and 2004, respectively. Dr. Moreland specializes in large-scale
    visualization and graphics and plays an active role in the development of several
    HPC products including Viskores, ParaView, VTK, IceT, and Catalyst. His current
    interests include the design and development of visualization algorithms and systems
    to run on multi-core, many-core, and future-generation computer hardware.
- Submission: proj126s1
  Status (This Stage): Accept (Confirmed)
  First/Given Names (first): Damien
  Last/Family Name (first): Lebrun-Grandie
  Email (first): lebrungrandt@ornl.gov
  Company/Institution (first): ORNL
  Website (first): https://www.ornl.gov/staff-profile/damien-lebrun-grandie
  SRP Project Title (first): Kokkos Tools
  What is the HPSF Project Name? (first): Kokkos
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; High Performance Computing; Performance Evaluation and Benchmarking;
    Software Engineering
  Brief Abstract (200 words) (first): 'This internship focuses on developing Kokkos
    Tools, a vital suite of libraries for analyzing and optimizing Kokkos applications
    without changing the source code. You will help expand the Kokkos Tools ecosystem
    by building: Performance & Energy Profiling tools to measure execution time, memory
    usage, and energy consumption. This work helps developers identify bottlenecks
    and optimize code for diverse hardware, including CPUs and GPUs. Code Sanity &
    Debugging tools to detect and diagnose common programming errors and invalid usage
    of the Kokkos API, ensuring code correctness. You will contribute to a major open-source
    project used globally in High-Performance Computing (HPC). You''ll gain hands-on
    experience in parallel programming, performance-portability, and the full software
    development lifecycle. This is a chance to build critical skills in performance
    analysis and debugging while connecting with the international HPC community.'
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): 'We''re
    looking for candidates with a passion for High-Performance Computing (HPC) and
    parallel programming. Relevant backgrounds could include Computer Science, Engineering,
    or a related technical field. Ideal interests and skills include: Experience with
    C++ (or a similar high-performance language). Familiarity with parallel programming
    models (e.g., CUDA, OpenMP, MPI, or Kokkos). An interest in performance analysis
    and finding ways to optimize code. A desire to contribute to a large-scale open-source
    project.'
  Lightning Talk Title (Maximum 10 words): 'Your Summer Project: Taming the World''s
    Fastest GPUs'
  Keywords (Maximum 20 words): Performance Portability; Exascale Computing; C++; Heterogeneous
    Architectures; GPU; Parallel Programming; Tooling / Profiling
  Biography (Maximum 200 words): Damien Lebrun-Grandié is a Senior Computational Scientist
    at Oak Ridge National Laboratory with over a decade of experience in the field.
    He holds a PhD in Nuclear Engineering from Texas A&M University, a MSc in Physics
    from the Karlsruhe Institute of Technology in Germany, and a MEng in Physics Engineering
    from Grenoble INP in France. His research focuses on developing algorithms and
    enabling technologies for solving large-scale, complex engineering, and scientific
    problems. As a founding member of the High Performance Software Foundation, Damien
    was instrumental in getting the organization started and continues to play a leading
    role on the Governing Board, representing the Technical Advisory Council. He is
    also the co-lead of the Kokkos C++ performance portability project, where he oversees
    a large international team of developers and researchers. Additionally, he represents
    ORNL on the C++ Standards Committee, where he has been a key contributor to foundational
    features for scientific computing like std::mdspan in C++23 and std::linalg for
    C++26.
- Submission: proj128s1
  Status (This Stage): Accept (Confirmed)
  First/Given Names (first): Todd
  Last/Family Name (first): Gamblin
  Email (first): tgamblin@llnl.gov
  Company/Institution (first): LLNL
  Department (first): Livermore Computing
  Photograph (first): 'jpg Information Type: jpgSize: 196KBUploaded: Oct 03MD5: 0e975e2d14afbe32e881a7785ba0a61cOriginal
    Name: me-greatwall-fron... view move to AWS'
  SRP Project Title (first): Spack at LLNL
  What is the HPSF Project Name? (first): Spack
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Applied Mathematics; Artificial Intelligence and Intelligent
    Systems; Computer Science; High Performance Computing; Open Source Software; Software
    Engineering
  Brief Abstract (200 words) (first): Depending on experience and interest, we will
    develop a project dealing with the open source Spack package manager (https://github.com/spack/spack)
    or the Spack package ecosystem (https://github.com/spack/spack-packages). Spack
    has become the de-facto package management tool for High Performance Computing,
    an area where software complexity is constantly rising. Spack helps users build,
    install, and manage software on laptops, desktops, and supercomputers. With over
    1,500 contributors and over 8,500 package recipes, Spak provides a valuable resource
    for HPC users around the world. Example projects would include new core features
    for Spack, including terminal UI improvements, performance improvements, or enhancements
    to Spack's solver or other capabilities. Projects could also focus on package
    recipe improvements, e.g. improvements to AI packages or GPU support, improvements
    to Spack's continuous integration system. We can tailor the project to the applicant's
    experience and interest. On this project, you’ll learn more about the core of
    Spack, how it builds software, and how large software ecosystems are sustained
    through community effort.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): For
    core Spack projects, we expect experience with Python and some Linux systems programming.
    An ideal candidate will have at least some experience with building and installing
    software, especially with build systems like CMake and Autotools. Low-level systems
    experience, e.g. UNIX process control, file I/O, and performance profiling are
    a plus. Experience with performance optimization and with using package managers,
    Spack or otherwise, are a plus.
- Submission: proj129s1
  Status (This Stage): Accept (Confirmed)
  First/Given Names (first): Andrew
  Last/Family Name (first): Myers
  Email (first): atmyers@lbl.gov
  Company/Institution (first): LBNL
  Department (first): Applied Mathematics
  Website (first): https://profiles.lbl.gov/22224-andrew-myers
  SRP Project Title (first): Python-driven workflows with AMReX
  What is the HPSF Project Name? (first): AMReX
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Applied Mathematics; High Performance Computing; Software Engineering
  Brief Abstract (200 words) (first): 'AMReX is a publicly available software framework
    designed for building massively parallel block- structured adaptive mesh refinement
    (AMR) applications. Simulation codes based on AMReX model a wide range phenomena
    from fields ranging from astrophysics and cosmology to plasma physics, earth systems
    modeling, multi-phase flow, epidemiology, cell biology, and more. While AMReX
    is written in C++, for this internship we are envisioning several projects that
    involve improving and expanding the Python interfaces to AMReX with the goal of
    supporting new AI/ML use cases, including: 1. Integrating simulations with ML-based
    Bayesian optimization workflows 2. Training fast surrogate models and incorporating
    those into simulations 3. Automatic differentiation of coupled C++ simulation
    and Python analysis code through tools like Enzyme. 4. Uncertainty quantification
    using frameworks like PyTUQ. The above workflows will be demonstrated on and evaluated
    with real-world AMReX-based application codes.'
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): Experience
    with Python is desired, other useful skills include experience with C++, AI/ML,
    and high-performance computing.
  Lightning Talk Title (Maximum 10 words): 'AMReX: Adaptive Mesh Refinement for Exascale'
  Keywords (Maximum 20 words): Adaptive Mesh Refinement; Math libraries; Scientific
    Computing; C++; Python; AI/ML; automatic differentiation; uncertainty quantification
  Biography (Maximum 200 words): Andrew joined Berkeley Lab in 2013 as a postdoctoral
    researcher in the Applied Numerical Algorithms Group. He is now a staff member
    in the Center for Computational Sciences and Engineering, where he designs and
    implements HPC algorithms for solving multiscale, multiphysics problems using
    structured adaptive meshes and particles. He is a core contributor to the AMReX
    adaptive mesh library, and also contributes to a number of AMReX-based simulation
    codes in subjects ranging from computational plasma physics to epidemiology. He
    was a member of the 2022 Gordon-Bell prize-winning team for kinetic plasma simulations
    with the WarpX Particle-in-Cell code, and received a Director's Award for Exceptional
    Scientific Achievement in 2023.
- Submission: proj134s1
  Status (This Stage): Accept Wave 2 (Confirmed)
  First/Given Names (first): Varun
  Last/Family Name (first): Kasireddy
  Email (first): vkasired@alumni.cmu.edu
  Company/Institution (first): Carnegie Mellon University
  Department (first): Robotics
  Website (first): https://teamchiron.ai
  SRP Project Title (first): Visual Language Model for Stand-off Triage Sensing
  What is the NAIRR Project Name? (first): LLM Training and Evaluation for Pandemic
    Prevention and Response
  'Please select all the topical areas that apply to your project: (first)': Computer
    Science
  Brief Abstract (200 words) (first): We build vision-language systems that help robots
    perform fast, reliable casualty triage. As our work involves practical edge deployment
    (e.g., NVIDIA Jetson), a critical aspect in our decision making is to balance
    algorithm accuracy with latency requirements. By Summer 2026, the project will
    be at a point where students will test and iterate on existing pipelines—video
    highlight extraction, robust person and blood segmentation, and Visual Question
    Answering (VQA) for scene understanding. Each week, we will run systems tests
    and score performance. Based on the results, students should quickly synthesize
    progress, create short presentations for the broader team, and help the project
    leads finetune models and manage versioning to push improvements for the next
    deployment. Work spans dataset preparation, annotation, benchmarking, and optimization
    on GPU clusters. The aim is clear tools that fit robotic workflows. Impact includes
    emergency response, safety monitoring, and human-robot teaming. It’s hands-on
    and fast-paced—you’ll see changes week to week and get to validate them on real
    hardware.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): "•
    Core: Python, basic Linux, Docker containerization, and comfort with Git/GitHub
    for fast iteration. • Robotics: ROS 2 basics (nodes, topics, launch files) to
    run weekly systems tests and integrate updated components. • Experiment tracking:
    Weights & Biases (W&B) for logging metrics, comparing runs, and sharing dashboards
    with the team. • Evaluation: Clear thinking about test scores, precision/recall,
    latency, and failure cases; ability to propose quick fixes. • Data pipelines:
    PyTorch, computer vision, segmentation, dataset curation/annotation (e.g., CVAT/FiftyOne),
    and simple GPU optimization. • Optional: Edge deployment (e.g., NVIDIA Jetson)"
  Lightning Talk Title (Maximum 10 words): Push AI-driven robots to the field
  Keywords (Maximum 20 words): Robotics; Multimodal Perception; Vision‑Language Models;
    Edge Computing; ROS 2; Real‑Time Evaluation; Reliable AI; Field Testing; Sensor
    Fusion; LiDAR
  Biography (Maximum 200 words): Varun Kasireddy is a Project Scientist at Carnegie
    Mellon University’s AirLab. His research focuses on multimodal perception, vision–language
    models, and learning on edge devices. He also collaborates with academic and industry
    partners, including efforts on autonomous aerial systems for object identification
    and tracking. Varun is committed to reproducible research, practical evaluation,
    and human‑in‑the‑loop development. He mentors students on concise experimentation,
    observability, and data quality, and enjoys designing small-scale prototypes that
    translate quickly to field trials. Through SRP, he aims to build a collaborative
    summer project that combines rigorous evaluation with scalable perception to deliver
    reliable robotic behaviors in real environments.
- Submission: proj136s1
  Status (This Stage): Accept Wave 2 (Confirmed)
  First/Given Names (first): Agniv
  Last/Family Name (first): Sengupta
  Email (first): agsengupta@ucsd.edu
  Company/Institution (first): University of California San Diego
  Department (first): Scripps Institution of Oceanography
  Photograph (first): 'jpg Information Type: jpgSize: 3MBUploaded: Oct 08MD5: f66aa5f053cad335f8215df3d1ee49f6Original
    Name: Agniv_Sengupta_ph... view move to AWS'
  Website (first): https://agsengupta.scrippsprofiles.ucsd.edu/
  SRP Project Title (first): AI Models for the Prediction of Extreme Weather Events
  What is the NAIRR Project Name? (first): Development of AI Data-driven Models and
    Very Large Ensembles for the Prediction of Atmospheric Rivers and Extreme Weather
    Events
  'Please select all the topical areas that apply to your project: (first)': Artificial
    Intelligence and Intelligent Systems; Atmospheric Sciences
  Brief Abstract (200 words) (first): Accurate weather forecasting has traditionally
    relied on numerical weather prediction models, which require significant computational
    resources. In this context, artificial intelligence (AI) models have revolutionized
    the domain of weather prediction in the past 2-3 years, emerging as computationally
    efficient alternatives. As part of our NAIRR Pilot project, we are developing
    such AI weather modeling and prediction capabilities over the North Pacific and
    the western United States, specifically for extreme weather phenomena such as
    atmospheric rivers (ARs). In this work, we utilize state-of-the-art AI advancements,
    including graph neural networks and Diffusion-based Generative AI methods. Additionally,
    we employ these models to generate a large number of realizations of future weather,
    enhancing the tracking of AR storms from their genesis over the Pacific to their
    impact over the U.S. West Coast.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): 'Interest
    in AI/ML, Meteorology, or Climate Science Experience with, or a desire to learn:
    * Python * Statistics * Data Analysis * Data Visualization * Machine Learning
    tools (e.g., PyTorch, TensorFlow, Keras, Scikit-learn) Coursework or experience
    in Statistics or Data Science is preferred. Familiarity with Machine Learning
    is a plus.'
  Any other comments (first): Opportunity to be co-hosted alongside a cohort of interns
    selected through the Scripps Institution of Oceanography (SIO)/CW3E Summer Internship
    Program at the beautiful SIO campus overlooking the Pacific Ocean.
  Lightning Talk Title (Maximum 10 words): AI Data-driven Models for the Prediction
    of Extreme Weather Events
  Keywords (Maximum 20 words): Weather; Meteorology; Artificial Intelligence; Machine
    Learning
  Biography (Maximum 200 words): Dr. Agniv Sengupta is a Sr. Computational Research
    Scientist and the Machine Learning Team Lead of the Center for Western Weather
    and Water Extremes (CW3E), Scripps Institution of Oceanography at UC San Diego.
    His research interests involve the prediction of high-impact weather events using
    artificial intelligence and machine learning. His current projects focus on improving
    the prediction skill of weather (0-10 days), subseasonal (1-6 weeks), and seasonal
    (1 to 6 months) forecasts in the Western United States. This involves exploring
    innovative algorithms and approaches, advancing models for predictions across
    multiple timescales, and developing decision-support tools and forecast products
    in coordination with stakeholders. Dr. Sengupta earned his Ph.D. (2020) and M.S.
    (2016) in Atmospheric and Oceanic Science from the University of Maryland College
    Park, and was subsequently a postdoctoral scholar (2020-21) at the NASA Jet Propulsion
    Laboratory (JPL) prior to joining CW3E.
- Submission: proj137s1
  Status (This Stage): Accept Wave 2 (Confirmed)
  First/Given Names (first): Reno
  Last/Family Name (first): Kriz
  Email (first): rkriz1@jhu.edu
  Company/Institution (first): Johns Hopkins University
  Department (first): Human Language Technology Center of Excellence
  Photograph (first): 'jpg Information Type: jpgSize: 2MBUploaded: Oct 08MD5: e62d9f661ef32b6fba6ad6916823825eOriginal
    Name: reno_headshot.jpeg view move to AWS'
  Website (first): https://hltcoe.jhu.edu/researcher/reno-kriz/
  SRP Project Title (first): 'SCALE 2026: Event Understanding and Summarization from
    Real-time Videos'
  What is the NAIRR Project Name? (first): Advancing Scientific Discovery through
    Multilingual/Multimodal Summarization at SCALE 2025/2026
  'Please select all the topical areas that apply to your project: (first)': Artificial
    Intelligence and Intelligent Systems; Computer Science; Electrical, Electronic,
    and Information Engineering; Informatics, Analytics and Information Science
  Brief Abstract (200 words) (first): understand real-time, multilingual video content
    is increasingly important. From smartphone footage of natural disasters to public
    livestreams near high-risk infrastructure, these unedited clips offer firsthand
    evidence of unfolding events. Combined with audio and embedded text, they form
    a rich multimodal source that remains underutilized in current retrieval-augmented
    generation systems. Especially for real-time situations, scientific advances grounding
    articles in video can combat misinformation and help journalists quickly synthesize
    information from non-traditional, cross-lingual platforms. SCALE 2026, a 10-week
    workshop hosted by the Human Language Technology Center of Excellence (HLTCOE)
    at Johns Hopkins University, provides a realistic setting for advancing real-world
    multimodal understanding. During the summer, we will evaluate modality-specific
    technologies for extracting relevant signals from raw video data. First-stage
    research areas include audio and visual event detection, speech and audio summarization,
    and OCR or visual frame analysis. These signals will inform the second stage,
    our primary task of multimodal retrieval-augmented generation. Given an information
    need and a collection of raw multilingual videos, the system must retrieve relevant
    content and generate a coherent summary of the most significant information. Second-stage
    research areas include multimodal information retrieval and multi-video summarization.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): We
    welcome participants with backgrounds or interests in natural language processing,
    computer vision, and multimodal technologies. Relevant experience might include
    work with large language or vision-language models, video or audio understanding,
    and multilingual or low-resource technologies. Participants interested in areas
    such as event detection, speech processing, optical character recognition, information
    retrieval, or summarization are especially encouraged to apply. SCALE projects
    are highly collaborative, bringing together researchers from diverse areas of
    expertise, so openness to interdisciplinary teamwork and shared problem-solving
    is essential.
  Any other comments (first): 'SCALE (the Summer Camp for Applied Language Exploration)
    is an annual 10-week research program hosted by the HLTCOE at Johns Hopkins University
    since 2009. For more on its history and past topics, see https://hltcoe.jhu.edu/research/scale/.
    SCALE 2026 builds on the two most recent workshops: SCALE 2024, focused on event-centric
    video retrieval, and SCALE 2025, which explored retrieval-augmented generation
    for request-guided summarization of multilingual sources.'
  Lightning Talk Title (Maximum 10 words): 'SCALE 2026: Event Understanding and Summarization
    from Real-time Videos'
  Keywords (Maximum 20 words): multimodal retrieval-augmented generation; multi-video
    summarization; video retrieval; speech/audio summarization; optical character
    recognition; audio/visual event detection; computer vision; speech processing
  Biography (Maximum 200 words): Reno Kriz is a research scientist at the Johns Hopkins
    University Human Language Technology Center of Excellence (HLTCOE). His primary
    research interests involve leverage large pre-trained models for a variety of
    natural language understanding tasks, including those crossing into other modalities,
    e.g., vision and speech understanding. These multimodal interests have recently
    involved the 2024 and 2026 Summer Camps for Language Exploration (SCALE) on event-centric
    video retrieval, understanding, and summarization. He received his PhD from the
    University of Pennsylvania where he worked with Chris Callison-Burch and Marianna
    Apidianaki on text simplification and natural language generation. Prior to that,
    he received BA degrees in Computer Science, Mathematics, and Economics from Vassar
    College.
- Submission: proj140s1
  Status (This Stage): Accept Wave 2 (Confirmed)
  First/Given Names (first): Shi Zhuo
  Last/Family Name (first): Looi
  Email (first): looi@caltech.edu
  Company/Institution (first): California institute of technology
  Department (first): Mathematics (Division of physics, mathematics and astronomy)
  Photograph (first): 'jpg Information Type: jpgSize: 114KBUploaded: Oct 09MD5: 38cdb0a0e0b33ef6becea12d2c884eb2Original
    Name: unnamed (1).jpg view move to AWS'
  Website (first): https://sites.google.com/view/s-looi/
  SRP Project Title (first): AI-Driven Methods for Discovering and Proving Mathematical
    Inequalities
  What is the NAIRR Project Name? (first): AI-Driven Methods for Discovering and Proving
    Mathematical Inequalities
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Applied Mathematics; Artificial Intelligence and Intelligent
    Systems; Computer Science; High Performance Computing; Performance Evaluation
    and Benchmarking; Training
  Brief Abstract (200 words) (first): Our proposed work advances AI for Accelerating
    Science and Discovery, a core focus area of the NAIRR Pilot, by developing a specialized,
    AI-driven framework for discovering and proving mathematical inequalities. Inequalities
    are foundational tools across scientific and engineering domains, from verifying
    stability in partial differential equations to bounding error terms in applied
    mathematics and physics. By combining large language models, reinforcement learning
    (RL), and symbolic computation, we aim to automate and accelerate the process
    of finding new results in both classical and cutting-edge mathematical research.
    This will facilitate the proof of inequalities and has the potential to enable
    new discoveries in science and engineering where precise mathematical bounds are
    important.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): Experience
    training models and/or handling datasets for language models
  Lightning Talk Title (Maximum 10 words): AI-Driven Discovery and Proof of Mathematical
    Inequalities
  Biography (Maximum 200 words): Looi works in mathematical analysis, evolutionary
    PDEs, and AI. A core part of his research in analysis and PDEs involves the study
    of inequalities, including functional and polynomial inequalities, which are intimately
    related to many areas of pure and applied mathematics. In the AI-math domain,
    his contributions include proving theorems on the controllability of self-attention
    in “What’s the Magic Word?”, leading the data team at Project Numina (winner of
    the 2024 AIMO Prize), and advancing Lean-4 formalization in PDEs. He is a founding
    scientific advisor to ScienceStack, a platform for interactive, machine-readable
    papers. His work aims to merge machine learning, formal methods, and math to build
    reliable and reproducible reasoning workflows in mathematics.
- Submission: proj141s1
  Status (This Stage): Accept Wave 2 (Confirmed)
  First/Given Names (first): Zhe
  Last/Family Name (first): Zhang
  Email (first): zhezhang@tamu.edu
  Company/Institution (first): Texas A&M University
  Department (first): Geography
  Photograph (first): 'jpg Information Type: jpgSize: 484KBUploaded: Oct 09MD5: 2b76038cf01c04c1ac1e9272dfa76666Original
    Name: zhesarina-zhang.jpg view move to AWS'
  SRP Project Title (first): Utilizing NAIRR Pilot Resources for Building Sustainable
    Blue Economy
  What is the NAIRR Project Name? (first): Utilizing NAIRR Pilot Resources for Building
    Sustainable Blue Economy
  'Please select all the topical areas that apply to your project: (first)': Educational
    Sciences; Environmental Biology; Environmental Biotechnology; Environmental Engineering;
    Other Earth and Environmental Sciences
  Brief Abstract (200 words) (first): The Gulf of America faces significant challenges
    for Blue Economy research, including environmental degradation from pollution
    and overfishing, as well as the impacts of natural disasters. These issues strain
    marine ecosystems and coastal communities, creating barriers to sustainability.
    Similarly, the mid-Atlantic region, such as Maryland, suffers from agriculture,
    urban runoff, and industrial activities that degrade water quality and significantly
    impact fish populations and the overall health of the fishery. Hawaii, meanwhile,
    encounters unique challenges due to its geographic isolation and heavy reliance
    on ocean resources. This project aims to address these challenges by establishing
    coordinated efforts to improve Blue Economy research in these regions, enhancing
    funding for innovative research, and strengthening partnerships across sectors
    to build a Blue Economy research network. This project will bring together students,
    faculty, and researchers from U.S. institutions, along with participants from
    broad fields, including GIScience, oceanography, computer science, biology, and
    civil engineering. The goal is to promote AI education and workforce development
    in Blue Economy research. Nowadays, AI has transformative potential to enhance
    blue economy research by providing advanced tools for data analysis, modeling,
    and decision-making.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): The
    workshop will offer training opportunities to help research communities effectively
    navigate NAIRR pilot resources, including learning how to access and use these
    resources for ocean and coastal sustainability analysis. All workshop and training
    materials will be made publicly available through a project GitHub repository
    and website, ensuring broad accessibility and ongoing learning opportunities.
    Participants will learn skills of cyberinfrastructure and high-performance computing,
    oceanography, disaster management, and coastal resilience planning.
  Lightning Talk Title (Maximum 10 words): Utilizing NAIRR Pilot Resources for Building
    Sustainable Blue Economy
  Keywords (Maximum 20 words): NAIRR, Cyberinfrastructure, Blue Economy, Artificial
    Intelligence, Oceanography, GIScience
  Biography (Maximum 200 words): Dr. Zhe Zhang is an Associate Professor in the Department
    of Geography at Texas A&M University. Dr. Zhang has served as Chair of the Cyberinfrastructure
    Specialty Group of the American Association of Geographers and was elected to
    the Board of Directors of the Cartography and Geographic Information Society.
    She also serves as Chair of the Research Committee of the University Consortium
    for Geographic Information Science. Her research focuses on developing spatial
    decision support systems by integrating advanced cyberinfrastructure, geospatial
    artificial intelligence, and participatory design to address critical challenges
    in disaster management and sustainability. Dr. Zhang serves as the Co-Principal
    Investigator of the Texas A&M FASTER High-Performance Supercomputer (over $3 million)
    and as a Co-Investigator of the Texas A&M ACES Supercomputer (over $12 million),
    both supported by the NSF. In addition, she serves as Principal Investigator on
    eight externally funded grants from (NSF, NASA, USDOT, NOAA, and National Geographic
    Society), totaling over $3 million. Dr. Zhang has been honored to receive both
    the Pathways Award from Texas A&M Faculty Affairs and the National Science Foundation
    CAREER Award in recognition of her impactful research.
- Submission: proj143s1
  Status (This Stage): Accept Wave 2 (Confirmed)
  First/Given Names (first): Avi
  Last/Family Name (first): Sahu
  Email (first): asahu@salud.unm.edu
  Company/Institution (first): UNM Comprehensive Cancer Center
  Department (first): Dept of Internal Medicine
  Photograph (first): 'png Information Type: pngSize: 1MBUploaded: Oct 10MD5: baa1c5fc89eaf1d6812fa40777e88ce6Original
    Name: headshot.png view move to AWS'
  Website (first): https://www.tumorai.org
  SRP Project Title (first): 'Bridging Molecules and Medicine: Explainable AI for
    Genetics and Imaging'
  What is the NAIRR Project Name? (first): 'Advancing Colorectal Cancer Diagnosis:
    A Multimodal AI Copilot for Real-Time Endoscopy'
  'Please select all the topical areas that apply to your project: (first)': Artificial
    Intelligence and Intelligent Systems; Biochemistry and Molecular Biology; Clinical
    Medicine; Health Sciences
  Brief Abstract (200 words) (first): "Millions of people face deep uncertainty in
    their fight against cancer. Two major hurdles often stand in the way of clear
    answers. First, genetic testing frequently returns ambiguous results called \"variants
    of unknown significance\" (VUS), leaving nearly 40% of patients in an anxious
    \"diagnostic limbo\" without clear medical guidance. Second, a nationwide shortage
    of specialists means that interpreting crucial medical images, like endoscopies,
    can be slow and inconsistent, delaying life-saving diagnoses. \U0001FA7A Our lab
    is pioneering a solution by building AI \"co-pilots\" for medicine. We have already
    developed the core technology: powerful AI models that can translate complex genetic
    data (Protein2Text) and interpret endoscopic images (EndoPilot). This project
    will focus on the most exciting application of these powerful tools. We will create
    Mutation2Text to demystify VUS with clear, understandable rationales. Concurrently,
    we will build MED-X, a framework where a team of our AIs work together (AI agents)
    to help doctors spot signs of colorectal cancer with greater accuracy. This project
    will deliver a unified pipeline that empowers clinicians, provides clear answers
    to patients, and makes expert-level care accessible to all."
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): 'We
    are building a diverse team and welcome collaborators from all backgrounds. Whether
    you are a coder, biologist, future doctor, or creative problem-solver, there is
    a place for you. We seek faculty/students with interests in: Technology & Data
    Science: Help build and train cutting-edge AI models using skills like Python
    and machine learning. Biology & Health Sciences: Use your background in genetics
    or life sciences to guide our AI’s reasoning and ensure its insights are clinically
    useful. Human-Centered Thinking: Help us create trustworthy, explainable AI that
    doctors can confidently use to improve patient care.'
  Lightning Talk Title (Maximum 10 words): Explainable AI Co‑Pilots for Genes and
    Endoscopy
  Keywords (Maximum 20 words): Explainable AI; Genomics; Variant interpretation; Endoscopy;
    Multimodal LLMs; Human‑AI collaboration; Cancer prevention; Precision oncology;
    Ovarian cancer; Colorectal cancer.
  Biography (Maximum 200 words): 'Avinash (“Avi”) Das Sahu, PhD is an assistant professor
    at UNM Comprehensive Cancer Center and Dept of Computer Science, where he leads
    th TumorAI lab (Tumorai.org). His group designs interpretable, clinician ready
    AI that links molecular signals to real world decisions in cancer care. The group
    builds AI “co pilots” across two fronts: (1) genomics, including Protein2Text
    and the forthcoming Mutation2Text to explain variants—especially VUS—with clear,
    rationale based text; and (2) medical imaging, where EndoPilot and the multi agent
    MED X framework support transparent, human in the loop analysis of endoscopic
    images for colorectal cancer. Guided by a simple aim—to “prevent the preventable
    and treat the treatable”— he collaborates closely with oncologists and geneticists
    to move these tools from algorithms to clinic ready prototypes. His work has been
    recognized with awards such as the OCRA CDRG (PI), NIH Pathway to Independence
    (K99/R00), and the Michelson Prize, following training at the University of Maryland/NHGRI
    and postdoctoral work at Dana Farber/Harvard and the Broad Institute. Beyond publishing
    in venues such as Cancer Discovery and Nature Communications, his lab emphasizes
    open science, inclusive mentoring, and deployment on high performance computing
    resources to broaden access to expert level decision.'
- Submission: proj144s1
  Status (This Stage): Accept Wave 2 (Confirmed)
  First/Given Names (first): Tuan
  Last/Family Name (first): Do
  Email (first): tdo@astro.ucla.edu
  Company/Institution (first): UCLA
  Photograph (first): 'jpg Information Type: jpgSize: 412KBUploaded: Oct 10MD5: 2ccc4331181e6d01ec92e4f2e1cc8b52Original
    Name: Tuan_Do_P8300064r... view move to AWS'
  Website (first): https://datalab.astro.ucla.edu/
  SRP Project Title (first): Integrating LLMs into Machine Learning for Physics and
    Astronomy Education
  What is the NAIRR Project Name? (first): Improving Access to Computation for Machine
    Learning for Physical Sciences Course
  'Please select all the topical areas that apply to your project: (first)': Artificial
    Intelligence and Intelligent Systems; Astronomy and Planetary Sciences; Particle
    and High-Energy Physics
  Brief Abstract (200 words) (first): This project is to study how to use large language
    models (LLMs) and related technologies into a course on Machine Learning for Physical
    Sciences at the upper division undergraduate level. LLMs are now a prominent technology
    in computer science and the industry, and many students have experience using
    them. However, students do not typically get the opportunity to setup their own
    LLM and do experiments on them. Specifically, the use of LLMs in scientific education
    is not well explored. This project aims to develop a course unit on both using
    existing LLMs as well as the underlying LLM architectures (e.g. transformers)
    for science. Potential projects include setting up and deploying local LLMs and
    examining their abilities to do physics research. Another is to combine images
    and text from astrophysics into a transformer to use data fusion for classification.
    By giving students experience in underlying technologies behind these tools, they
    will become more knowledgeable and responsible users of AI and develop skills
    useful for their careers.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): Background
    in teaching, designing lab courses, and/or deploying large language models.
  Lightning Talk Title (Maximum 10 words): Developing an LLM curriculum for AI/ML
    in Physical Sciences courses
  Keywords (Maximum 20 words): LLMs; transformers; science education; Physical Sciences;
    Physics; Astrophysics; Data Science; Lab Classes
  Biography (Maximum 200 words): Tuan Do is an Associate Professor at UCLA in the
    Physics and Astronomy Department. He is the PI of the UCLA Astrophysics Data Lab.
    He got his undergraduate degrees in Physics and Astrophysics from UC Berkeley
    and his Astrophysics Ph.D. at UCLA. His research focuses on translating ML/AI
    models for Astrophysics applications. He created the first Machine Learning for
    Physical Science course at UCLA.
- Submission: proj146s1
  Status (This Stage): Accept Wave 2 (Confirmed)
  First/Given Names (first): Haohan
  Last/Family Name (first): Wang
  Email (first): haohanw@illinois.edu
  Company/Institution (first): University of Illinois Urbana Champaign
  Department (first): School of Information Sciences
  Photograph (first): 'jpg Information Type: jpgSize: 2MBUploaded: Oct 10MD5: bcb77a700a959547b7266fb7e6ca282fOriginal
    Name: haohanwang.jpg view move to AWS'
  Website (first): https://haohanwang.github.io/
  SRP Project Title (first): 'Toward Redefining Disease Taxonomy: Scaling Transcriptomic
    Analysis with Agentic AI Systems'
  What is the NAIRR Project Name? (first): 'Toward Redefining Disease Taxonomy: Scaling
    Transcriptomic Analysis with Agentic AI Systems'
  'Please select all the topical areas that apply to your project: (first)': Basic
    Medicine; Biochemistry and Molecular Biology; Health Sciences
  Brief Abstract (200 words) (first): The project aims to redefine how diseases are
    classified by using agentic artificial intelligence—a new generation of self-revising,
    collaborative AI systems—to analyze large-scale human transcriptomic data. Today’s
    biomedical research relies on rigid pipelines that struggle to integrate data
    across tissues, populations, and rare conditions. We will build an AI framework
    composed of autonomous reasoning agents that continuously analyze and validate
    public datasets, learning to correct themselves and adapt to missing metadata
    or unexpected patterns. These agents will uncover disease relationships directly
    from molecular signals rather than from pre-defined diagnostic categories. The
    outcome is a data-driven taxonomy of disease—linking common and rare conditions
    through shared regulatory signatures—that could reshape how medicine understands
    biological variability. Students will join a cross-disciplinary team at the intersection
    of AI, computational biology, and open science, contributing to a system that
    learns science itself.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): We
    welcome students from computer science, data science, biology, or related fields
    who are curious about how AI can advance scientific discovery. Interest in coding,
    statistics, or genomics is helpful but not required. The most important traits
    are curiosity, persistence, and comfort working across disciplines. Experience
    with Python, R, or machine learning frameworks is a plus, but students can learn
    these skills during the project.
  Any other comments (first): Students will gain experience working with large biological
    datasets and intelligent systems that operate autonomously. The environment emphasizes
    mentorship, open collaboration, and publication-quality research. Outstanding
    participants may continue with the lab through independent study or joint conference
    submissions.
  Lightning Talk Title (Maximum 10 words): Toward Redefining Disease Taxonomy
  Keywords (Maximum 20 words): Disease should not be defined by clinical manifestation,
    but by the underlying mechanism
  Biography (Maximum 200 words): Haohan Wang is an assistant professor in the School
    of Information Sciences at the University of Illinois Urbana-Champaign. His research
    focuses on the development of trustworthy machine learning methods for computational
    biology and healthcare applications, such as decoding the genomic language of
    Alzheimer's disease. In his work, he uses statistical analysis and deep learning
    methods, with an emphasis on data analysis using methods least influenced by spurious
    signals. Wang earned his PhD in computer science through the Language Technologies
    Institute of Carnegie Mellon University where he works with Professor Eric Xing.
    In 2019, Wang was recognized as the Next Generation in Biomedicine by the Broad
    Institute of MIT and Harvard because of his contributions in dealing with confounding
    factors with deep learning.
- Submission: proj149s1
  Status (This Stage): Accept Wave 2 (Confirmed)
  First/Given Names (first): Steven
  Last/Family Name (first): Fernandes
  Email (first): stevenfernandes@creighton.edu
  Company/Institution (first): Creighton University
  Department (first): Computer Science, Design and Journalism
  Photograph (first): 'jpg Information Type: jpgSize: 5MBUploaded: Oct 15MD5: 10265fc9952999fb714e9630a89d5355Original
    Name: Steven_Fernandes.jpg view move to AWS'
  Website (first): https://www.creighton.edu/campus-directory/fernandes-steven-l
  SRP Project Title (first): Building Generative AI Applications
  What is the NAIRR Project Name? (first): CSC 590 - Building Generative AI Applications
  'Please select all the topical areas that apply to your project: (first)': Artificial
    Intelligence and Intelligent Systems; Computer Science; Health Sciences; Software
    Engineering
  Brief Abstract (200 words) (first): This project explores how to build artificial
    intelligence systems that can create, understand, and assist with real-world tasks.
    We'll work on three exciting types of applications. First, we'll create an AI
    that can generate new content, such as images. This has applications everywhere
    from art and entertainment to marketing and product design. Second, we'll build
    AI that can search through large collections of information and provide accurate,
    helpful answers by combining what it finds with its ability to generate responses.
    Think of this as creating smarter search tools or assistants that can actually
    comprehend documents and assist people in making informed decisions. Third, we'll
    develop autonomous AI agents that can complete multi-step tasks independently,
    like digital assistants that handle scheduling, research, or workflow automation.
    This work matters because these technologies are transforming every industry from
    healthcare to education to creative fields. Understanding how to build them responsibly
    puts you at the forefront of real innovation. We welcome collaborators from all
    backgrounds and experience levels, whether you're interested in coding, design,
    ethics, user experience, or simply curious about what AI can do. You'll gain practical
    hands-on skills while working on applications that could genuinely help people
    in their everyday lives.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): We
    welcome collaborators from diverse backgrounds and with varying experience levels.
    Helpful skills include basic programming in any language, an interest in how AI
    systems work, or experience with data and information. Creative thinking, problem
    solving, user experience design, and perspectives on ethics or responsible AI
    development are all valuable. Most importantly, we're looking for curiosity, willingness
    to learn, and enthusiasm for exploring how these technologies can solve real problems.
  Any other comments (first): 'If possible, I would be interested in considering the
    following two students from Creighton University: (1) Our PhD student, Vignesh
    Rathinavelpandian Anandavel, applied for the student track and was also included
    in my initial faculty track application. (2) The undergraduate student, Sara Avila,
    was only included as a student in my initial faculty track application.'
  Lightning Talk Title (Maximum 10 words): Generative AI for Cochlear Hair Cell Detection
  Keywords (Maximum 20 words): Generative AI; Deep Learning; Computer Vision; Machine
    Learning; Medical Image Processing.
  Biography (Maximum 200 words): I am an Assistant Professor of Computer Science at
    Creighton University, where I have taught and mentored students in computer science,
    data science, and health informatics since joining in July 2020. My research focuses
    on developing advanced deep learning models for applications in computer vision,
    medical imaging, and natural language processing. Before my current role, I completed
    postdoctoral research in the Department of Computer Science at the University
    of Central Florida from September 2018 to June 2020, contributing to projects
    funded by the Defense Advanced Research Projects Agency (DARPA), National Science
    Foundation (NSF), and Royal Bank of Canada (RBC), with a focus on deep learning
    and computer vision. Additionally, I conducted postdoctoral research in the Department
    of Electrical and Computer Engineering at the University of Alabama at Birmingham
    from July 2017 to August 2018, working on National Institutes of Health (NIH)-funded
    projects related to deep learning and medical image processing. My research has
    obtained compute credits through NAIRR Pilot Classroom, NAIRR Startup, Amazon
    Web Services, and Google Cloud Platform. I have published articles in high-impact
    AI venues, including NeurIPS, CVPR, ECCV, and ICCV.
- Submission: proj150s1
  Status (This Stage): Accept (Unconfirmed)
  First/Given Names (first): Axel
  Last/Family Name (first): Huebl
  Email (first): axelhuebl@lbl.gov
  Company/Institution (first): Lawrence Berkeley National Laboratory
  Department (first): Accelerator Technology & Applied Physics
  Photograph (first): 'jpg Information Type: jpgSize: 227KBUploaded: Oct 19MD5: cb9acf1f3bdb4b05b9c432931341da3cOriginal
    Name: Axel_Huebl.jpg view move to AWS'
  Website (first): https://github.com/ax3l/
  SRP Project Title (first): Novel Exascale & AI Workflows with WarpX
  What is the HPSF Project Name? (first): WarpX
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Applied Mathematics; Fluid and Plasma Physics; High Performance
    Computing; Open Source Software; Particle and High-Energy Physics; Performance
    Evaluation and Benchmarking; Software Engineering
  Brief Abstract (200 words) (first): 'We are envisioning several projects that involve
    improving and expanding the performance or scientific workflows using WarpX, including:
    1. Parallel data post-processing with DASK and openPMD. 2. Automatic differentiation
    of C++ simulations through tools like Enzyme. 3. Implementation of numerical algorithms
    for the modeling of plasmas, lasers, and particle beams, with applications in
    fusion and/or accelerator physics. 4. Training fast AI/ML surrogate models. Incorporate
    those into simulations, integrated research infrastructures, updating models in
    real-time from experimental and simulation data as they become available, and/or
    informing operation in experiments. The above implementations and workflows will
    be demonstrated on and evaluated with WarpX simulations in fusion and particle
    accelerator physics.'
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): We
    are looking for people interested in developing new code (C++, Python), implement
    numerics, or new workflows to address timely challenges in fusion and particle
    accelerator science. Ideally, you already have experience with C++, Python and
    Git/GitHub and are eager to be embedded in an open, interdisciplinary team.
- Submission: doeproj101s1
  Status (This Stage): Accept (Unconfirmed)
  First/Given Names (first): Khaled
  Last/Family Name (first): Ibrahim
  Email (first): kzibrahim@lbl.gov
  Company/Institution (first): Lawrence Berkeley National Laboratory
  Department (first): Computer Science
  Website (first): https://profiles.lbl.gov/21065-khaled-ibrahim
  SRP Project Title (first): Performant Scientific Workflows in HPC Environments
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Artificial Intelligence and Intelligent Systems; Computer Science;
    High Performance Computing; Performance Evaluation and Benchmarking
  Brief Abstract (200 words) (first): 'Modern scientific workflows are rapidly evolving,
    integrating LLMs, AI, and simulation codes to control, predict, and model complex
    discovery processes. Managing these intricate workflows effectively is crucial
    for leveraging HPC resources, preventing underutilization, and accelerating scientific
    progress. This project addresses these challenges through two main approaches:
    1- Workload Instrumentation to Profile and Model Performance: By instrumenting
    workflow components, we gather detailed performance metrics to identify bottlenecks,
    understand resource consumption, and predict performance under various loads,
    enabling proactive optimization. 2- Orchestration of Resource Scheduling to Improve
    User Experience: Building on performance insights, we develop sophisticated scheduling
    mechanisms to dynamically allocate HPC resources, minimizing wait times, maximizing
    throughput, and enhancing user experience for scientists by accelerating experiment
    execution and model iteration.'
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): 'Programming
    Languages: C++, Python; Profiling infrastructures: Nvidia tools'
  Lightning Talk Title (Maximum 10 words): Performant Scientific Workflows in HPC
    Environments
  Keywords (Maximum 20 words): High Performance Computing HPC/AI workflows
  Biography (Maximum 200 words): Khaled Ibrahim is a member of the Parallel Performance
    and AI Nexus (PPAN) group in the Computing Sciences Area. He is working on various
    research projects on high performance computing focusing on runtime systems, programming
    models, performance modeling and optimization, and computer architectures. Khaled
    Ibrahim came to Berkeley Lab in 2009, after working in INRIA, France. He obtained
    his PhD in computer engineering from North Carolina State University.
- Submission: doeproj102s1
  Status (This Stage): Accept (Unconfirmed)
  First/Given Names (first): Andy
  Last/Family Name (first): Nonaka
  Email (first): AJNonaka@lbl.gov
  Company/Institution (first): LBNL
  Department (first): Applied Mathematics
  Website (first): https://ccse.lbl.gov/index.html
  SRP Project Title (first): High-Performance Multiphysics and Multiscale Modeling
    with AMReX
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Applied Mathematics; Atmospheric Sciences; Computer Science;
    Electrical, Electronic, and Information Engineering; Fluid and Plasma Physics;
    High Performance Computing; Open Source Software; Performance Evaluation and Benchmarking;
    Software Engineering
  Brief Abstract (200 words) (first): The Center for Computational Sciences and Engineering
    (CCSE) at LBNL is a high-performance modeling and simulation group interested
    in applications described by complex partial differential equations including
    fluids (industrial, biological, and micro/nanoscale), plasma physics, microelectronics,
    and environmental flows. The underlying software framework we develop and use
    is called AMReX, a GPU/exascale-enabled block-structured adaptive mesh refinement
    software framework that also includes particle/mesh, embedded boundary, and linear
    solver capabilities. We also develop data-driven / machine-learning enhancement,
    and code coupling strategies to both accelerate and increase the fidelity of our
    codes. We are looking for collaborators with common interests in the computer
    science, applied mathematics, and/or application science aspects of research performed
    within CCSE.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): C++,
    python, numerical methods, partial differential equations, domain knowledge in
    fluids, plasmas, microelectronics, and/or environmental flow.
  Lightning Talk Title (Maximum 10 words): High-Performance Multiphysics and Multiscale
    Modeling with AMReX
  Keywords (Maximum 20 words): partial differential equations, structured mesh, particle/mesh,
    data/ML-driven model acceleration, industrial fluids, biofluids, micro/nanoscale
    fluids, plasmas, microelectronics, environmental flow.
  Biography (Maximum 200 words): Andy Nonaka is a Staff Scientist and Group Lead of
    the Center for Computational Sciences and Engineering at Lawrence Berkeley National
    Laboratory. His research interests include high-performance implementations of
    multiphysics and multiscale algorithms for partial differential equations, with
    a recent emphasis on electrodynamical, fluid dynamical, and material science applications.
    More generally, he is interested in adaptive structured mesh algorithms, particle
    and particle/mesh methods, linear solvers, and machine learning techniques to
    accelerate scientific discovery.
- Submission: doeproj103s1
  Status (This Stage): Accept (Unconfirmed)
  First/Given Names (first): arianna
  Last/Family Name (first): formenti
  Email (first): ariannaformenti@lbl.gov
  Company/Institution (first): LBNL
  SRP Project Title (first): Physics simulations and code development for plasma and/or
    accelerator physics
  'Please select all the topical areas that apply to your project: (first)': Fluid
    and Plasma Physics; High Performance Computing; Open Source Software; Particle
    and High-Energy Physics
  Brief Abstract (200 words) (first): 'This research project will be hosted by the
    Accelerator Modeling Program group at Lawrence Berkeley National Laboratory. AMP
    is a program within the Accelerator Technology and Applied Physics Division at
    Berkeley Lab that focuses on HPC to model particle accelerators, laser-plasma
    interactions, beam physics and plasma devices, and nuclear fusion. With this project,
    you will have the opportunity to contribute to ongoing research and gain hands-on
    experience in the field of computational physics within an open and team-science
    driven environment. Specifically, you will contribute to the development of the
    Beam, Plasma & Accelerator Simulation Toolkit by working in the WarpX team, an
    open-source massively-parallel particle-in-cell code that was awarded the prestigious
    2022 ACM Gordon Bell Prize. You will participate in the advancement of theoretical
    and computational plasma and beam accelerator physics, through one or more of
    the various activities that occur in the program, which offers a wide range of
    possibilities such as: Investigating physics through simulation campaigns to support
    theoretical and/or experimental studies with the codes developed in the program;
    Improving our computational tools or methods for better performances on supercomputers,
    or for simulating new physics; Exploring novel numerical schemes, algorithms,
    and AI/ML approaches to improve simulations’ reliability.'
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): "*
    Python and/or C++ development * improve GPU-accelerated HPC open source codes
    * AI/ML * supercomputers such as Perlmutter (NERSC) * Python notebooks & presentations
    for demonstration/training/debugging. A background/study in physics, computer
    science or applied math is desired and the focus of the project will be adjusted
    accordingly. To stand out from the crowd, you might already have experience with
    Python and C++, know how to use GitHub, or have run simulations before."
  Lightning Talk Title (Maximum 10 words): Meet out team at LBNL and the Exascale
    code WarpX
  Keywords (Maximum 20 words): particle; accelerator; hpc; plasma; physics; fusion;
    particle-in-cell;
  Biography (Maximum 200 words): Arianna Formenti is a post-doc in the Accelerator
    Technology and Applied Physics Division at Lawrence Berkeley National Laboratory.
    Her research interests include modeling of future particle colliders – such as
    Higgs factories and 10 TeV-level wakefield colliders – and fusions plasmas with
    advanced simulations. She is a maintainer of the code WarpX, which is part of
    the BLAST simulation toolkit. She received a BSc and MSC in Mathematical Engineering
    and a PhD in Energy and Nuclear Science and Technology from Politecnico di Milano,
    Italy. Arianna is also committed to science education, workforce development,
    and outreach.
- Submission: doeproj104s1
  Status (This Stage): Accept (Unconfirmed)
  First/Given Names (first): Tianyi
  Last/Family Name (first): Shi
  Email (first): tianyishi@lbl.gov
  Company/Institution (first): Lawrence Berkeley National Laboratory
  SRP Project Title (first): Develop tensor algorithms in Python
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Applied Mathematics; High Performance Computing; Open Source
    Software
  Brief Abstract (200 words) (first): A wide range of applications involve multidimensional
    data as observations or solutions, and these data sets are often referred to as
    tensors. The storage cost of tensors grows exponentially with respect to the dimensionality,
    also known as "the curse of dimensionality", so researchers develop various data-sparse
    tensor formats for lower storage and faster computations. This project focuses
    on a special tensor format called the tensor-train (TT) format. We have developed
    some data-centric algorithms to factor a given tensor into TT representations.
    Our proposed algorithms can also be parallelized, and we can use them in analyzing
    large data sets, solving partial differential equations, and conducting statistical
    learning. In order to compare with state-of-the-art data-centric TT decomposition
    packages, we would like to implement our algorithms in Python, specifically with
    PyTorch and MPI4Py, using highly optimized linear algebra kernels and distributed
    memory parallelism. Then we can perform a thorough comparison between our proposed
    algorithms and the existing ones.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): 'Interests
    or background in numerical linear algebra and parallel computing. Desired skills:
    know how to code in Python, preferably PyTorch.'
  Lightning Talk Title (Maximum 10 words): Tensor Computations in Python
  Keywords (Maximum 20 words): Numerical linear algebra; tensor computations; parallel
    algorithms; Python.
  Biography (Maximum 200 words): Tianyi Shi is a postdoctoral scholar at Lawrence
    Berkeley National Laboratory in the Scalable Solvers Group within the Computing
    Sciences Area. He received his Ph.D. in Applied Mathematics from Cornell University.
    Tianyi’s research focuses on developing efficient and scalable algorithms for
    sparse and data-sparse matrices and tensors, with applications in computational
    chemistry and high-performance computing. His work involves designing shared-
    and distributed-memory parallel CPU and GPU codes in C, C++, and CUDA, and conducting
    large-scale experiments on supercomputers.
- Submission: doeproj105s1
  Status (This Stage): Accept (Unconfirmed)
  First/Given Names (first): Phillip
  Last/Family Name (first): Thomas
  Email (first): pthomas@lbl.gov
  Company/Institution (first): Lawrence Berkeley National Laboratory
  Department (first): NERSC
  SRP Project Title (first): Simulating Vibrational Spectra of Molecules
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Applied Mathematics; High Performance Computing; Materials Engineering;
    Open Source Software; Software Engineering
  Brief Abstract (200 words) (first): Our group is interested in simulating infrared
    spectra of molecules from first principles calculations. We have a code, called
    "MLCP", which solves the high-dimensional eigenvalue problem to generate the energy
    levels. We are interested in building an automated simulation pipeline which integrates
    MLCP with other tools to rapidly simulate vibrational spectra of new systems.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): High
    Performance Computing Programming Chemistry and/or physics
  Lightning Talk Title (Maximum 10 words): Simulating Vibrational Spectra of Molecules
  Keywords (Maximum 20 words): Fortran; python; spectroscopy; chemistry; physics;
    high performance computing; simulation; workflow; pipeline; automation
  Biography (Maximum 200 words): Phillip is an Application Performance Engineer at
    NERSC. His areas of expertise include Fortran, GPU programming, and algorithms
    related to tackling the Curse of Dimensionality. His efforts at NERSC involve
    improving the performance of material science applications. Before coming to NERSC,
    Phillip developed compute kernels for Wave Computing in Santa Clara, California.
    Prior to that Phillip worked as a post-doctoral researcher in quantum reaction
    dynamics at Queen's University in Ontario, Canada and at Leiden University in
    the Netherlands. He also has experience in experimental molecular spectroscopy
    from a post-doctoral fellowship at The Ohio State University. Phillip's Ph.D.
    thesis topic was spectroscopy and simulation of reactive organic molecules.
- Submission: doeproj106s1
  Status (This Stage): Accept (Unconfirmed)
  First/Given Names (first): Kevin A.
  Last/Family Name (first): Brown
  Email (first): kabrown@anl.gov
  Company/Institution (first): Argonne National Laboratory (ANL)
  Department (first): Mathematics and Computer Science Division
  Website (first): https://www.anl.gov/profile/kevin-a-brown
  SRP Project Title (first): Analyzing and Modeling Large Scale Infrastructure
  'Please select all the topical areas that apply to your project: (first)': Artificial
    Intelligence and Intelligent Systems; Computer Science; Electrical, Electronic,
    and Information Engineering; High Performance Computing; Informatics, Analytics
    and Information Science; Infrastructure and Instrumentation; Other Computer and
    Information Sciences; Performance Evaluation and Benchmarking; Software Engineering;
    Statistics and Probability
  Brief Abstract (200 words) (first): 'Large-scale computing infrastructure—including
    supercomputers and wide-area research networks—underpins breakthroughs in science
    and engineering. Yet the scale and complexity of these systems make them difficult
    to deploy, operate, and optimize. They produce massive volumes of telemetry and
    logs that must be distilled into actionable insight, and faults can cascade across
    subsystems, degrading reliability and productivity if not detected and mitigated
    quickly. Our work brings together complementary capabilities to study, design,
    and optimize these infrastructures: • System and workload modeling that combines
    AI, parallel discrete-event simulation (PDES), and fast surrogate models • Scalable
    log and telemetry analysis, including automated, AI-assisted pipelines • Anomaly
    detection and failure prediction to improve resilience • Network performance benchmarking,
    measurement, and analysis to guide planning and operations'
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): "-
    Basic programming experience is an asset"
  Lightning Talk Title (Maximum 10 words): Analyzing and Modeling Large-Scale Infrastructure
  Keywords (Maximum 20 words): networking supercomputing HPC ESnet AI Artificial intelligence
    Resilience Failure analysis Performance analysis
  Biography (Maximum 200 words): Kevin A. Brown is the Assistant Computer Scientist
    at Argonne National Laboratory where he investigates new designs for supercomputer
    networks. He received his B.Sc. from the University of Technology, Jamaica (UTech)
    and his M.Sc. and Ph.D. in Mathematical and Computing Science from the Tokyo Institute
    of Technology. His prior work experience includes serving as a Unix Systems Administrator
    at Digicel (Jamaica) Ltd. and as a postdoctoral appointee in the Argonne Leadership
    Computing Facility focused on exascale interconnect performance evaluation.
- Submission: doeproj107s1
  Status (This Stage): Accept (Unconfirmed)
  First/Given Names (first): Sai Krishna Kanth
  Last/Family Name (first): Hari
  Email (first): hskkanth@lanl.gov
  Company/Institution (first): Los Alamos National Laboratory
  SRP Project Title (first): Scalable Algorithms for Critical Infrastructure Network
    Planning
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Applied Mathematics; Artificial Intelligence and Intelligent
    Systems; Chemical Engineering; Civil Engineering; Computer Science; Electrical,
    Electronic, and Information Engineering; High Performance Computing; Hydrology
    and Water Resources; Infrastructure and Instrumentation; Mechanical Engineering
  Brief Abstract (200 words) (first): Critical infrastructure networks—such as power
    grids, water distribution systems, and natural gas pipelines—form the backbone
    of modern society. Planning their design, daily operation, and expansion requires
    repeatedly solving large-scale, complex optimization problems. These problems
    are computationally challenging due to nonlinear and nonconvex flow models, discrete
    decision variables, and the vast scale of network systems. This project focuses
    on developing scalable optimization algorithms for such critical infrastructure
    systems. We leverage techniques such as linear relaxations, spatial and temporal
    decomposition, and problem-structure exploitation to design methods capable of
    handling realistic, high-fidelity flow models efficiently. The outcomes aim to
    enable faster and more reliable decision-making in infrastructure planning and
    operation—directly supporting the Department of Energy’s mission to enhance the
    resilience, efficiency, and security of national energy and water networks.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): Interest
    in optimization algorithms, energy or network systems, or applied mathematics;
    experience with Julia, Python, C++, or MATLAB.
  Lightning Talk Title (Maximum 10 words): Scalable Algorithms for Critical Infrastructure
    Network Planning
  Keywords (Maximum 20 words): Optimization, critical infrastructure, energy systems,
    network modeling, algorithms, decomposition, applied mathematics, computational
    methods.
  Biography (Maximum 200 words): Research scientist with interests in critical infrastructure
    network planning, autonomous vehicle planning and applied optimization. Background
    in civil and mechanical engineering.
- Submission: doeproj108s1
  Status (This Stage): Accept (Unconfirmed)
  First/Given Names (first): Kesheng (John)
  Last/Family Name (first): Wu
  Email (first): kwu@lbl.gov
  Company/Institution (first): Lawrence Berkeley National Laboratory (LBNL)
  Website (first): https://profiles.lbl.gov/20161-john-wu/
  SRP Project Title (first): Advanced Modeling for Prediction and Anomaly Detection
    in Network Operations
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Artificial Intelligence and Intelligent Systems; Infrastructure
    and Instrumentation
  Brief Abstract (200 words) (first): 'As we approach the summer of 2026, our goal
    is to develop and deploy advanced modeling capabilities for predicting hardware
    failures and detecting external configuration anomalies in our network infrastructure.
    This project aims to leverage machine learning and data analytics to improve network
    stability, reduce unplanned outages, and enhance overall network efficiency. We
    will focus on two key areas: (1) Predicting Hardware Failures: By analyzing log
    and telemetry data, we will develop models to predict hardware failures in networking
    equipment, enabling proactive replacement and minimizing downtime. (2) Detecting
    Network Configuration Anomalies: We will create a tool to analyze received network
    configuration data, identify routing path changes, and notify engineers of anomalies,
    ensuring swift response to potential disruptions. Through this project, we will
    apply advanced modeling techniques to drive business outcomes, including: - Improved
    network stability and reduced unplanned outages - Enhanced predictive capabilities
    for hardware failures and configuration anomalies - Data-driven decision-making
    for network operations and maintenance By investing in advanced modeling and analytics,
    we will take a proactive approach to network operations, ensuring a more resilient
    and efficient network infrastructure for the summer of 2026 and beyond.'
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): Strong
    analytics skills are must. Computer networking knowledge is desired.
  Lightning Talk Title (Maximum 10 words): Advanced Modeling for Prediction and Anomaly
    Detection in Network Operations
  Keywords (Maximum 20 words): Predictive Modeling Anomaly Detection Network Stability
    Machine Learning Data Analytics Network Operations
  Biography (Maximum 200 words): Dr. Kesheng (John) Wu leads multiple R&D endeavors
    focused on advanced technologies and testbeds at the Scientific Networking Division
    of Lawrence Berkeley National Laboratory. These projects aim to expedite data
    transfer among DOE user facilities, implement in-network storage and computational
    resources for intricate scientific workflows, and explore algorithms, strategies,
    and practices to enhance the efficiency of network operations. Additionally, Dr.
    Wu's team is tasked with developing and managing networking testbeds, providing
    the broader research community with platforms to explore future generations of
    networking technologies and optimize their utilization. These testbeds encompass
    conventional optical networking alongside cutting-edge quantum communication capabilities.
- Submission: doeproj109s1
  Status (This Stage): Accept (Unconfirmed)
  First/Given Names (first): Talita
  Last/Family Name (first): Perciano
  Email (first): tperciano@lbl.gov
  Company/Institution (first): Lawrence Berkeley National Laboratory
  Department (first): Scientific Data Division
  SRP Project Title (first): 'AQuA-DATA: Advanced Quantum Algorithms for Diverse Applications
    and Theoretical Advancements in Science'
  'Please select all the topical areas that apply to your project: (first)': Applied
    Mathematics; Computer Science; Other Computer and Information Sciences
  Brief Abstract (200 words) (first): This project aims to bridge the gap between
    theoretical quantum advantages and practical scientific applications by developing
    quantum algorithms and quantum machine learning methods, focusing on efficient
    data encoding to achieve quantum utility across diverse scientific domains. Our
    proposal centers on developing a sophisticated suite of quantum algorithms tailored
    to harness classical data for advanced scientific applications. We emphasize efficient
    quantum data encoding, coupled with error mitigation approaches, as a pivotal
    strategy to bridge the gap between theoretical quantum capabilities and practical
    use across diverse scientific domains. Targeting classical data, which parallels
    the concept of classical channels in quantum physics, our approach involves specific
    data reduction techniques and sparsity to refine and simplify the data to serve
    as input to our quantum algorithms. This makes it more amenable to quantum processing,
    particularly focusing on computationally intensive components of larger data analysis
    pipelines. Our methods encompass both pure quantum and hybrid quantum-classical
    algorithms.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): Computer
    Science, software development, quantum algorithms, quantum computing, applied
    math
  Lightning Talk Title (Maximum 10 words): Machine Learning and Quantum Algorithms
    for Science
  Keywords (Maximum 20 words): Machine learning; applied math; quantum algorithms;
    probabilistic graphical models; high performance computing.
  Biography (Maximum 200 words): Dr. Perciano is a Research Scientist in the AI &
    Learning Systems group and the Computational Biosciences group, at Lawrence Berkeley
    National Laboratory. She conducts research in the areas of quantum computing,
    quantum algorithms, image analysis, machine learning, probabilistic graphical
    models, and high-performance computing motivated by the incredible challenges
    around scientific data generated by computational models, simulations, and experiments.
    Her research focuses on mathematical foundations for new methods, on the implementation
    of scalable methods, and on platform-portability. Her goal is to develop powerful,
    mathematically-grounded, scalable algorithms that meet the requirements needed
    to analyze current and future scientific datasets acquired in user data facilities.
    She has built a diverse collaboration network throughout the years in fields such
    as materials science, biosciences, chemistry, among others.
- Submission: doeproj110s1
  Status (This Stage): Accept (Unconfirmed)
  First/Given Names (first): Arjun
  Last/Family Name (first): Sharma
  Email (first): asharm1@sandia.gov
  Company/Institution (first): Sandia National Labs
  Department (first): Applied and Computational Mathematics
  SRP Project Title (first): AI + Physics for Better Propellers/ turbines
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Applied Mathematics; Artificial Intelligence and Intelligent
    Systems; Environmental Engineering; Fluid and Plasma Physics; High Performance
    Computing; Mechanical Engineering; Open Source Software; Performance Evaluation
    and Benchmarking; Software Engineering
  Brief Abstract (200 words) (first): 'Propellers and turbines, spinning blades on
    drones, aircraft, ships, and wind turbines, have been modeled since before powerful
    computers. Engineers built quick “low-order” tools such as blade-element models
    (slice each blade into small segments), actuator-line models (represent the blade
    as a line of force), and vortex methods (capture swirling wakes). These tools
    are fast and great for early design exploration but can miss important flow features.
    By contrast, high-fidelity computational fluid dynamics (CFD) resolves those details
    but is often too slow for everyday use. This project blends the best of both worlds.
    We keep the fast physics model and train a neural network to learn the missing
    piece, the difference between low-order predictions and high-fidelity results.
    This “grey-box” approach respects physics while data improves it. We focus on
    practical performance measures, how much push (thrust) and how hard to spin (torque),
    rather than every pressure or velocity detail, keeping the method simple for early
    design. Summer work may include building a benchmark dataset, designing and training
    neural network, visualizing results, and packaging a reusable tool. Students can
    focus on coding, physics, or visualization based on interest. The outcome: better
    early designs for aircraft, ships, and clean-energy systems.'
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): "•
    Curiosity about physics and data • Some programming (Python or MATLAB—or any language)
    • Basic data handling/plotting (matplotlib, or similar) • Comfort with algebra/calculus;
    willingness to learn new tools or mathematics • Willingness to learn, ask questions,
    and work as a team Nice to have: basic ML; exposure to aerodynamics/CFD; familiarity
    with HPC clusters; interest in aircraft, drones, or clean energy."
  Lightning Talk Title (Maximum 10 words): 'Faster, Trustworthy Fluids: Al + physics
    for Propellers, Wings, Aerosols.'
  Keywords (Maximum 20 words): propellers, turbines, drones, aircraft, airfoils, aerosols,
    droplets, ice, turbulence, aerodynamics, thrust, torque, machine-learning, neural-networks,
    design optimization, climate, air-quality, SINDy
  Biography (Maximum 200 words): Arjun Sharma is a Postdoctoral Appointee at Sandia
    National Laboratories (Computer Science Research Institute). He works at the intersection
    of fluid mechanics, computing, and machine learning, building fast, trustworthy
    models for design and discovery. Recent projects include improving classic wing
    aerodynamics with learned corrections, non local transport of nutrients in bacterial
    suspension, air-sea flux exchange in the DOE’s climate model, and machine learning
    physics parametrization for climate models. He codes in Python (JAX/PyTorch),
    Matlab and Fortran, uses GPUs, and runs larger studies on HPC clusters, with an
    emphasis on clear, reproducible workflows and understanding physical mechanisms.
    Arjun earned a Ph.D. in Mechanical Engineering (Applied Mathematics minor) from
    Cornell University. Before graduate school he worked in high-performance engineering
    at Rolls-Royce (aeroacoustics) and in Formula One (aerodynamics). He has taught
    and TA’d core courses in thermodynamics and fluid dynamics and enjoys mentoring
    students at different levels. For SRP, Arjun offers flexible projects where students
    can lean into coding, physics, or visualization and leave with a portfolio-ready
    artifact (well-documented repo, figures, and a short write-up). His mentoring
    style is supportive and structured, weekly one-on-ones, code reviews, and clear
    milestones, with opportunities for co-authorship when results warrant
- Submission: doeproj111s1
  Status (This Stage): Accept (Unconfirmed)
  First/Given Names (first): Justin
  Last/Family Name (first): Wozniak
  Email (first): woz@anl.gov
  Company/Institution (first): Argonne National Laboratory
  Department (first): Data Science & Learning
  Website (first): https://www.anl.gov/profile/justin-m-wozniak
  SRP Project Title (first): Applying Performance Prediction to Live Filesystems
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Applied Mathematics; Artificial Intelligence and Intelligent
    Systems; Open Source Software; Performance Evaluation and Benchmarking; Visualization
    and Human-Computer Systems
  Brief Abstract (200 words) (first): Large shared filesystems can be an unpredictable
    environment for running large scientific workflows. Our team has developed a performance
    collection and prediction software package. We would now like to improve the software,
    make it more portable and easy to use, and run it on more real-world filesystems.
    The team in this project will run the data collection and prediction tools on
    live systems with real applications. The research aspect will be in how to interpret
    and visualize the resulting data. Possible applications include light source experiments
    from the Advanced Photon Source and data management workflows from epidemics modeling.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): Linux
    Shell scripting Machine learning
  Lightning Talk Title (Maximum 10 words): Prediction and resilience for distributed
    workflows
  Keywords (Maximum 20 words): workflows;hpc;filesystems;prediction
  Biography (Maximum 200 words): Wozniak designs and implements workflow systems for
    scientific applications and deep learning workloads, combining techniques from
    high-performance computing and distributed computing. He has extensive experience
    integrating advanced computing techniques in collaboration with the health, experimental,
    and simulation sciences.
- Submission: doeproj112s1
  Status (This Stage): Accept (Unconfirmed)
  First/Given Names (first): Bert
  Last/Family Name (first): de Jong
  Email (first): wadejong@lbl.gov
  Company/Institution (first): Lawrence Berkeley National Laboratory
  SRP Project Title (first): AI agents for chemical and materials science
  'Please select all the topical areas that apply to your project: (first)': Chemical
    Engineering; Computer Science; Condensed Matter Physics
  Brief Abstract (200 words) (first): Discovering new materials or chemical processes
    is a complex and time-consuming endeavor, often requiring countless experiments,
    intricate analysis, and sometimes even serendipitous discoveries. Inverse design
    has the promise to rationally discover new materials and processes. Supported
    by artificial intelligence, inverse design can dramatically accelerate this process
    by analyzing vast datasets, predicting material properties, and guiding experimental
    design—reducing both the time and uncertainty involved in scientific discovery.
    Our team is working on developing agents, integrated with machine learning and
    large language models, self-driving experiments and HPC simulations.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): Physical
    chemistry or materials knowledge would be helpful Good understanding of AI and
    ML methods, some knowledge of agentic AI.
  Lightning Talk Title (Maximum 10 words): AI agents for chemical and materials science
  Keywords (Maximum 20 words): AI; ML; chemical processes; materials; discovery; inverse
    design
  Biography (Maximum 200 words): Bert de Jong is the Director of the Quantum Systems
    Accelerator, which is part of the National Quantum Initiative. In addition, de
    Jong is the Team Director of the Accelerated Research for Quantum Computing (ARQC)
    Team MACH-Q, funded by DOE ASCR, focused on developing software stacks for near-term
    quantum computing devices. In addition, de Jong has a program in AI and machine
    learning to understand biomolecular processes, and discover new materials and
    molecular crystals for gas adsorption. de Jong serves as the Department Head for
    Computational Sciences, and leads the Applied Computing for Scientific Discovery
    Group, which advances scientific computing by developing and enhancing applications
    in key disciplines, as well as developing HPC, quantum and AI tools and libraries
    for addressing general problems in computational science.
- Submission: doeproj113s1
  Status (This Stage): Accept (Unconfirmed)
  First/Given Names (first): Graham
  Last/Family Name (first): Harper
  Email (first): gbharpe@sandia.gov
  Company/Institution (first): Sandia National Laboratories
  SRP Project Title (first): Multilevel Machine Learning for Material Modeling
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Applied Mathematics; High Performance Computing; Materials Engineering
  Brief Abstract (200 words) (first): Multilevel methods are a class of algorithms
    which accelerate solutions of large problems by solving a sequence of smaller
    problems. Recent developments have shown multilevel methods may be used to train
    large neural networks by instead training a sequence of smaller networks. The
    benefits of these approaches are derived from the comparatively lower costs of
    training smaller networks. This is particularly effective for Kolmogorov-Arnold
    Networks (KANs), which are a type of neural network which learn individual activation
    functions. This also allows for development of mathematical theory related to
    polynomial approximation of functions. These theories and algorithms may be used
    to accelerate training of neural networks for a variety of different applications,
    such as material modeling engineering applications.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): Mathematics
    theory Machine learning software and theory Computer science and programming Engineering
    and materials
  Lightning Talk Title (Maximum 10 words): Multilevel Training for Machine Learning
  Keywords (Maximum 20 words): Mathematics; Multilevel Methods; Machine Learning;
    Neural Networks; Kolmogorov-Arnold Networks; Computer Science; Material Modeling;
    Engineering;
  Biography (Maximum 200 words): Graham Harper is a staff member at Sandia National
    Laboratories in the scientific machine learning department. He has expertise in
    finite element methods, domain decomposition, linear solvers, multigrid, earth
    system modeling, and machine learning. He has developed high-performance software
    for several libraries, including Trilinos, deal.II, and Neko. In his free time,
    Graham enjoys 3D printing, electronics repair, and gardening.
- Submission: doeproj114s1
  Status (This Stage): Accept (Unconfirmed)
  First/Given Names (first): Roel
  Last/Family Name (first): Van Beeumen
  Email (first): rvanbeeumen@lbl.gov
  Company/Institution (first): Lawrence Berkeley National Laboratory
  Department (first): Applied Mathematics and Computational Research Division
  Website (first): https://www.roelvanbeeumen.be
  SRP Project Title (first): Simulation of quantum algorithms
  'Please select all the topical areas that apply to your project: (first)': Applied
    Mathematics; Computer Science; Condensed Matter Physics; High Performance Computing;
    Open Source Software; Performance Evaluation and Benchmarking
  Brief Abstract (200 words) (first): Current and near-term quantum computers, also
    known as noisy intermediate-scale quantum (NISQ) computers, are characterized
    by low qubit counts, short qubit decoherence times, and high gate error rates.
    On the other hand, rapid progress in both quantum hardware and software results
    in continuous simulation needs of novel/modified quantum algorithms. The QCLAB
    and QCLAB++ simulation software packages, developed at LBNL, are respectively
    an object-oriented MATLAB toolbox and a fully templated C++ package for constructing,
    representing, and simulating quantum circuits. Designed with an emphasis on numerical
    stability, efficiency, and performance, QCLAB provides a reliable platform for
    prototyping and testing quantum algorithms. For advanced performance needs, QCLAB++
    serves as a complementary C++ package optimized for GPU-accelerated quantum circuit
    simulations. Together, QCLAB and QCLAB++ form a comprehensive toolkit, balancing
    the simplicity of MATLAB scripting with the computational power of GPU acceleration.
    Project ideas could include improving (CPU/GPU) performance, adding different
    noise models, implementing qudits functionalities, and expanding the quantum algorithms'
    base.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): 'Specific
    background depends on the specific project focus, but generally: software development
    (Matlab, C++), quantum computing, applied mathematics, etc.'
  Lightning Talk Title (Maximum 10 words): Quantum Computing meets Numerical Linear
    Algebra
  Keywords (Maximum 20 words): Quantum Computing Quantum Algorithms NISQ Quantum Linear
    Algebra Matlab C++ CPU/GPU Performance Optimization State Vector Simulation
  Biography (Maximum 200 words): 'Roel Van Beeumen is a Staff Scientist in the Applied
    Mathematics and Computational Research Division at Berkeley Lab. His research
    interests range from numerical linear algebra and software for solving large-scale
    and high dimensional eigenvalue problems to quantum computing and quantum algorithms.
    He earned his PhD in Engineering Science: Computer Science (2015) at KU Leuven
    in Belgium, from which he also holds Master degrees in Mathematical Engineering
    (2010) and in Archaeology (2011).'
- Submission: doeproj115s1
  Status (This Stage): Accept (Unconfirmed)
  First/Given Names (first): Zhe
  Last/Family Name (first): Bai
  Email (first): zhebai@lbl.gov
  Company/Institution (first): Lawrence Berkeley National Laboratory
  Department (first): Applied Mathematics and Computational Research
  Website (first): https://profiles.lbl.gov/39980-zhe-bai
  SRP Project Title (first): Sequential modeling of multi-scale dynamical systems
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Applied Mathematics; Artificial Intelligence and Intelligent
    Systems; High Performance Computing
  Brief Abstract (200 words) (first): This project develops advanced sequential models
    to analyze time-series data. The goal is to capture the complex, multi-scale,
    path-dependent relationships using historic event data. The model is expected
    to learn both short-term and long-term temporal patterns for an overall reliable
    forecast.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): Proficient
    in coding; experienced in optimizing neural networks; interested in transformers
    and/or high performance computing.
  Lightning Talk Title (Maximum 10 words): Sequential modeling of multi-scale dynamical
    systems
  Keywords (Maximum 20 words): Advanced sequential modeling; hierarchical learning;
    time series forecasting; dynamical systems.
  Biography (Maximum 200 words): Zhe Bai is a computational science researcher in
    the Applied Mathematics and Computational Research Division of the Computing Sciences
    Area at Lawrence Berkeley National Laboratory. Her research interests lie in the
    area of data-driven modeling and model order reduction, including dynamic mode
    decomposition, scientific machine learning and sparse algorithms for large-scale
    computation and simulation. Cultivated interdisciplinary research and collaborations
    spanning the fields of computational science and engineering, her work focuses
    on AI-based modeling that couples first-principles with data-driven approaches
    to understand, estimate and control high-dimensional physical systems.
- Submission: doeproj116s1
  Status (This Stage): Accept (Unconfirmed)
  First/Given Names (first): Kathryn
  Last/Family Name (first): Maupin
  Email (first): kmaupin@sandia.gov
  Company/Institution (first): Sandia National Laboratories
  Department (first): Optimization and Uncertainty Quantification
  SRP Project Title (first): Uncertainty Quantification of Displacement Damage Models
  'Please select all the topical areas that apply to your project: (first)': Applied
    Computer Science; Applied Mathematics; Computer Science; Other Computer and Information
    Sciences; Particle and High-Energy Physics; Statistics and Probability
  Brief Abstract (200 words) (first): As the third pillar of science, computational
    simulation has allowed scientists to explore, observe, and test physical regimes
    previously thought to be unattainable. High-fidelity models are derived from physical
    principles and calibrated to experimental data. However, missing or unknown physics
    and measurement, experimental, and numerical errors give rise to uncertainties
    in the model form and parameter values in even the most trustworthy models. Thus,
    rigorous calibration and validation of a computational model is paramount to its
    effective us as a predictive tool. The popularity of the Bayesian paradigm stems
    from its natural integration of measurement and model uncertainties. A systematic
    approach to model validation, progressing from parameter and quantity of interest
    identification to sensitivity analysis, calibration, and validation, is applied
    to a drift-diffusion simulation code called Charon. Charon allows the computational
    qualification of semiconductor devices subjected to displacement damage. *Sandia
    National Laboratories is a multimission laboratory managed and operated by National
    Technology & Engineering Solutions of Sandia, LLC, a wholly owned subsidiary of
    Honeywell International Inc., for the U.S. Department of Energy’s National Nuclear
    Security Administration under contract DE-NA0003525.
  Desired relevant skills, background, or interests (don't be too prescriptive) (first): Coding
    (any language), Command Line Interface, Desire to learn
  Lightning Talk Title (Maximum 10 words): Uncertainty Quantification of Displacement
    Damage Models
  Keywords (Maximum 20 words): Bayesian methods; model calibration; model validation;
    uncertainty quantification; model discrepancy; model form error.
  Biography (Maximum 200 words): Kathryn Maupin is a Principal Member of the Technical
    Staff at Sandia National Laboratories. Motivated by a passion for transforming
    uncertainty into actionable insights, Kathryn leverages her extensive expertise
    in model validation, model form error quantification, and Bayesian analyses to
    drive innovative solutions that enhance research outcomes. Kathryn earned her
    PhD in Computational Science, Engineering, and Mathematics, along with her M.S.
    in Computational and Applied Mathematics, both from The University of Texas at
    Austin. Her fascination with mathematical modeling began at the University of
    California, San Diego, where she completed her B.A. in Applied Mathematics. When
    she is not immersed in data and algorithms, Kathryn enjoys the chaos of family
    life with her three children and three dogs. Looking ahead, Kathryn aspires to
    continue pushing the boundaries of computational science while encouraging others
    to confront ubiquitous uncertainty in their work.
